{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration 1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "df = pd.read_excel('./data/results.xlsx')\n",
    "df['uc'] = df['qc'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "df['ud'] = df['qd'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "df['momentumc'] = 998 * df['uc'] ** 2 / (1e-3 * 0.6)\n",
    "df['momentumd'] = 1.29 * df['ud'] ** 2 / (1e-3 * 0.6)\n",
    "df['viscosityc'] = (0.2563 * df['peg'] ** 1.7663 + 0.7890) * 1e-3 * df['uc'] / (1e-3 * 0.6) ** 2\n",
    "df['viscosityd'] = 18.6 * 1e-6 * df['ud'] / (1e-3 * 0.6) ** 2\n",
    "df['interfacec'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "df['interfaced'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "df['Wo/w'] = df['w'] / 3\n",
    "df['qc/qd'] = df['qc'] / df['qd']\n",
    "df['rec'] = df['momentumc'] / df['viscosityc']\n",
    "df['red'] = df['momentumd'] / df['viscosityd']\n",
    "df['cac'] = df['viscosityc'] / df['interfacec']\n",
    "df['cad'] = df['viscosityd'] / df['interfaced']\n",
    "df['wec'] = df['momentumc'] / df['interfacec']\n",
    "df['wed'] = df['momentumd'] / df['interfaced']\n",
    "\n",
    "w_peg_r_iter1 = {\n",
    "    'w':   [6, 6, 10, 10, 10, 10, 15, 15, 15, 15],\n",
    "    'peg': [0, 5,  0,  5, 10, 15,  0,  5, 10, 15],\n",
    "    'r':   [2, 3,  1,  2,  3,  4,  3,  4,  5,  2],\n",
    "}\n",
    "ridxs = []\n",
    "for w, peg, r in zip(w_peg_r_iter1['w'], w_peg_r_iter1['peg'], w_peg_r_iter1['r']):\n",
    "    ridxs.extend(df[(df['w'] == w) & (df['peg'] == peg) & (df['r'] == r)].index)\n",
    "df = df.iloc[ridxs]\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== di/Wi ================\n",
      "mean rmse: 0.183\tmean r2: 0.850\n",
      "======================================\n",
      "\n",
      "=============== occurrence ================\n",
      "mean p: 0.796\t\tmean macro_p: 0.803\n",
      "mean r: 0.796\t\tmean macro_r: 0.771\n",
      "===========================================\n",
      "\n",
      "=============== do/Wo ================\n",
      "mean rmse: 0.081\tmean r2: 0.796\n",
      "======================================\n",
      "\n",
      "=============== sigma ================\n",
      "mean rmse: 4.588\tmean r2: 0.347\n",
      "======================================"
     ]
    }
   ],
   "source": [
    "cols = ['Wo/w', 'qc/qd', 'rec', 'red', 'cac', 'cad', 'wec', 'wed']\n",
    "score = {'di_rmse': [], 'di_r2': [], 'p': [], 'macro_p': [], 'r': [], 'macro_r': [], 'd_rmse': [], 'd_r2': [], 'p_rmse': [], 'p_r2': []}\n",
    "di_models = []\n",
    "o_models = []\n",
    "d_models = []\n",
    "p_models = []\n",
    "for i in range(10):\n",
    "    kfold = KFold(5, shuffle=True, random_state=i)\n",
    "    for fold in range(5):\n",
    "        train_idxs, test_idxs = list(kfold.split(df[cols], df['state']))[fold]\n",
    "        train_df = df.iloc[train_idxs].copy()\n",
    "        test_df = df.iloc[test_idxs].copy()\n",
    "        train_x, test_x = train_df[cols], test_df[cols]\n",
    "        train_y_di = (train_df['prev_d32'] / 0.6).to_numpy()\n",
    "        test_y_di = (test_df['prev_d32'] / 0.6).to_numpy()\n",
    "        di_model = RandomForestRegressor(random_state=12)\n",
    "        di_model.fit(train_x, train_y_di)\n",
    "        di_models.append(di_model)\n",
    "        test_p_di = di_model.predict(test_x)\n",
    "        score['di_rmse'].append(np.round(((test_p_di - test_y_di)**2).mean()**0.5, 4))\n",
    "        score['di_r2'].append(np.round(r2_score(test_y_di, test_p_di), 4))\n",
    "        train_df['di/Wi'] = di_model.predict(train_df[cols])\n",
    "        test_df['di/Wi'] = di_model.predict(test_df[cols])\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_o = train_df['state'].to_numpy()\n",
    "        test_y_o = test_df['state'].to_numpy()\n",
    "        o_model = RandomForestClassifier(random_state=2)\n",
    "        o_model.fit(train_x, train_y_o)\n",
    "        o_models.append(o_model)\n",
    "        test_p_o = o_model.predict(test_x)\n",
    "        p_weight = 1 / 2 / np.array([(test_p_o == i).sum() for i in test_p_o])\n",
    "        r_weight = 1 / 2 / np.array([(test_y_o == i).sum() for i in test_y_o])\n",
    "        score['p'].append(np.round((test_p_o == test_y_o).mean(), 4))\n",
    "        score['r'].append(np.round((test_p_o == test_y_o).mean(), 4))\n",
    "        score['macro_p'].append(np.round(((test_p_o == test_y_o) * p_weight).sum(), 4))\n",
    "        score['macro_r'].append(np.round(((test_p_o == test_y_o) * r_weight).sum(), 4))\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_d = (train_df['post_d32'] / (0.1 * train_df['w'])).to_numpy()\n",
    "        test_y_d = (test_df['post_d32'] / (0.1 * test_df['w'])).to_numpy()\n",
    "        d_model = RandomForestRegressor(random_state=0)\n",
    "        d_model.fit(train_x, train_y_d)\n",
    "        d_models.append(d_model)\n",
    "        test_p_d = d_model.predict(test_x)\n",
    "        score['d_rmse'].append(np.round(((test_p_d - test_y_d)**2).mean()**0.5, 4))\n",
    "        score['d_r2'].append(np.round(r2_score(test_y_d, test_p_d), 4))\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_p = train_df['post_d32_polydispersity'].to_numpy()\n",
    "        test_y_p = test_df['post_d32_polydispersity'].to_numpy()\n",
    "        p_model = RandomForestRegressor(random_state=12)\n",
    "        p_model.fit(train_x, train_y_p)\n",
    "        p_models.append(p_model)\n",
    "        test_p_p = p_model.predict(test_x)\n",
    "        score['p_rmse'].append(np.round(((test_p_p - test_y_p)**2).mean()**0.5, 4))\n",
    "        score['p_r2'].append(np.round(r2_score(test_y_p, test_p_p), 4))\n",
    "\n",
    "print('=============== di/Wi ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['di_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['di_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')\n",
    "\n",
    "print('=============== occurrence ================')\n",
    "print('mean p: %.3f' % np.mean(score['p']), end='\\t\\t')\n",
    "print('mean macro_p: %.3f' % np.mean(score['macro_p']), end='\\n')\n",
    "print('mean r: %.3f' % np.mean(score['r']), end='\\t\\t')\n",
    "print('mean macro_r: %.3f' % np.mean(score['macro_r']), end='\\n')\n",
    "print('===========================================', end='\\n\\n')\n",
    "\n",
    "print('=============== do/Wo ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['d_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['d_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')\n",
    "\n",
    "print('=============== sigma ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['p_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['p_r2']), end='\\n')\n",
    "print('======================================', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16257708853614988\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w</th>\n",
       "      <th>peg</th>\n",
       "      <th>r</th>\n",
       "      <th>o_uncertainty</th>\n",
       "      <th>d_uncertainty</th>\n",
       "      <th>p_uncertainty</th>\n",
       "      <th>uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.211652</td>\n",
       "      <td>0.018225</td>\n",
       "      <td>0.033510</td>\n",
       "      <td>0.263387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.211652</td>\n",
       "      <td>0.017628</td>\n",
       "      <td>0.033485</td>\n",
       "      <td>0.262765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.211652</td>\n",
       "      <td>0.018360</td>\n",
       "      <td>0.032018</td>\n",
       "      <td>0.262029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.012187</td>\n",
       "      <td>0.037654</td>\n",
       "      <td>0.249841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.035590</td>\n",
       "      <td>0.247689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     w  peg  r  o_uncertainty  d_uncertainty  p_uncertainty  uncertainty\n",
       "13  10   10  6       0.211652       0.018225       0.033510     0.263387\n",
       "14  10   10  7       0.211652       0.017628       0.033485     0.262765\n",
       "12  10   10  5       0.211652       0.018360       0.032018     0.262029\n",
       "22  15   10  7       0.200000       0.012187       0.037654     0.249841\n",
       "21  15   10  6       0.200000       0.012100       0.035590     0.247689"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "qcs = [200, 400, 600, 800, 1000]\n",
    "ws = [6, 10, 15]\n",
    "pegs = [10]\n",
    "rs = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "exp_w_peg_r_combos = list(zip(w_peg_r_iter1['w'], w_peg_r_iter1['peg'], w_peg_r_iter1['r']))\n",
    "cand_df = {'w': [], 'peg': [], 'r': [], 'o_uncertainty': [], 'd_uncertainty': [], 'p_uncertainty': []}\n",
    "for w, peg, r in itertools.product(ws, pegs, rs):\n",
    "    if (w, peg, r) in exp_w_peg_r_combos: continue\n",
    "    test_df = {'w': [], 'peg': [], 'r': [], 'qc': [], 'qd': []}\n",
    "    for qc in qcs:\n",
    "        test_df['w'].append(w)\n",
    "        test_df['peg'].append(peg)\n",
    "        test_df['r'].append(r)\n",
    "        test_df['qc'].append(qc)\n",
    "        test_df['qd'].append(qc / r)\n",
    "    test_df = pd.DataFrame(test_df)\n",
    "    test_df['uc'] = test_df['qc'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "    test_df['ud'] = test_df['qd'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "    test_df['momentumc'] = 998 * test_df['uc'] ** 2 / (1e-3 * 0.6)\n",
    "    test_df['momentumd'] = 1.29 * test_df['ud'] ** 2 / (1e-3 * 0.6)\n",
    "    test_df['viscosityc'] = (0.2563 * test_df['peg'] ** 1.7663 + 0.7890) * 1e-3 * test_df['uc'] / (1e-3 * 0.6) ** 2\n",
    "    test_df['viscosityd'] = 18.6 * 1e-6 * test_df['ud'] / (1e-3 * 0.6) ** 2\n",
    "    test_df['interfacec'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "    test_df['interfaced'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "    test_df['Wo/w'] = test_df['w'] / 3\n",
    "    test_df['qc/qd'] = test_df['qc'] / test_df['qd']\n",
    "    test_df['rec'] = test_df['momentumc'] / test_df['viscosityc']\n",
    "    test_df['red'] = test_df['momentumd'] / test_df['viscosityd']\n",
    "    test_df['cac'] = test_df['viscosityc'] / test_df['interfacec']\n",
    "    test_df['cad'] = test_df['viscosityd'] / test_df['interfaced']\n",
    "    test_df['wec'] = test_df['momentumc'] / test_df['interfacec']\n",
    "    test_df['wed'] = test_df['momentumd'] / test_df['interfaced']\n",
    "    cand_df['w'].append(w)\n",
    "    cand_df['peg'].append(peg)\n",
    "    cand_df['r'].append(r)\n",
    "    o_preds = []\n",
    "    d_preds = []\n",
    "    p_preds = []\n",
    "    for i in range(len(di_models)):\n",
    "        test_df['di/Wi'] = di_models[i].predict(test_df[cols])\n",
    "        o_preds.append(o_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "        d_preds.append(d_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "        p_preds.append(p_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "    cand_df['o_uncertainty'].append(np.stack(o_preds).std(axis=0).mean())\n",
    "    cand_df['d_uncertainty'].append(np.stack(d_preds).std(axis=0).mean() / )\n",
    "    cand_df['p_uncertainty'].append(np.stack(p_preds).std(axis=0).mean() / df['post_d32_polydispersity'].max())\n",
    "cand_df = pd.DataFrame(cand_df)\n",
    "cand_df['uncertainty'] = cand_df['o_uncertainty'] + cand_df['d_uncertainty'] + cand_df['p_uncertainty']\n",
    "cand_df.sort_values('uncertainty', inplace=True, ascending=False)\n",
    "print(cand_df['uncertainty'].mean())\n",
    "cand_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "df = pd.read_excel('./data/results.xlsx')\n",
    "df['uc'] = df['qc'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "df['ud'] = df['qd'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "df['momentumc'] = 998 * df['uc'] ** 2 / (1e-3 * 0.6)\n",
    "df['momentumd'] = 1.29 * df['ud'] ** 2 / (1e-3 * 0.6)\n",
    "df['viscosityc'] = (0.2563 * df['peg'] ** 1.7663 + 0.7890) * 1e-3 * df['uc'] / (1e-3 * 0.6) ** 2\n",
    "df['viscosityd'] = 18.6 * 1e-6 * df['ud'] / (1e-3 * 0.6) ** 2\n",
    "df['interfacec'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "df['interfaced'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "df['Wo/w'] = df['w'] / 3\n",
    "df['qc/qd'] = df['qc'] / df['qd']\n",
    "df['rec'] = df['momentumc'] / df['viscosityc']\n",
    "df['red'] = df['momentumd'] / df['viscosityd']\n",
    "df['cac'] = df['viscosityc'] / df['interfacec']\n",
    "df['cad'] = df['viscosityd'] / df['interfaced']\n",
    "df['wec'] = df['momentumc'] / df['interfacec']\n",
    "df['wed'] = df['momentumd'] / df['interfaced']\n",
    "\n",
    "w_peg_r_iter2 = {\n",
    "    'w':   [6, 6, 10, 10, 10, 10, 15, 15, 15, 15, 10, 10],\n",
    "    'peg': [0, 5,  0,  5, 10, 15,  0,  5, 10, 15, 10, 10],\n",
    "    'r':   [2, 3,  1,  2,  3,  4,  3,  4,  5,  2,  5,  7],\n",
    "}\n",
    "ridxs = []\n",
    "for w, peg, r in zip(w_peg_r_iter2['w'], w_peg_r_iter2['peg'], w_peg_r_iter2['r']):\n",
    "    ridxs.extend(df[(df['w'] == w) & (df['peg'] == peg) & (df['r'] == r)].index)\n",
    "df = df.iloc[ridxs]\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== di/Wi ================\n",
      "mean rmse: 0.158\tmean r2: 0.866\n",
      "======================================\n",
      "\n",
      "=============== occurrence ================\n",
      "mean p: 0.775\t\tmean macro_p: 0.781\n",
      "mean r: 0.775\t\tmean macro_r: 0.777\n",
      "===========================================\n",
      "\n",
      "=============== do/Wo ================\n",
      "mean rmse: 0.090\tmean r2: 0.843\n",
      "======================================\n",
      "\n",
      "=============== sigma ================\n",
      "mean rmse: 5.449\tmean r2: 0.175\n",
      "======================================"
     ]
    }
   ],
   "source": [
    "cols = ['Wo/w', 'qc/qd', 'rec', 'red', 'cac', 'cad', 'wec', 'wed']\n",
    "score = {'di_rmse': [], 'di_r2': [], 'p': [], 'macro_p': [], 'r': [], 'macro_r': [], 'd_rmse': [], 'd_r2': [], 'p_rmse': [], 'p_r2': []}\n",
    "di_models = []\n",
    "o_models = []\n",
    "d_models = []\n",
    "p_models = []\n",
    "for i in range(10):\n",
    "    kfold = KFold(5, shuffle=True, random_state=i)\n",
    "    for fold in range(2):\n",
    "        train_idxs, test_idxs = list(kfold.split(df[cols], df['state']))[fold]\n",
    "        train_df = df.iloc[train_idxs].copy()\n",
    "        test_df = df.iloc[test_idxs].copy()\n",
    "        train_x, test_x = train_df[cols], test_df[cols]\n",
    "        train_y_di = (train_df['prev_d32'] / 0.6).to_numpy()\n",
    "        test_y_di = (test_df['prev_d32'] / 0.6).to_numpy()\n",
    "        di_model = RandomForestRegressor(random_state=12)\n",
    "        di_model.fit(train_x, train_y_di)\n",
    "        di_models.append(di_model)\n",
    "        test_p_di = di_model.predict(test_x)\n",
    "        score['di_rmse'].append(np.round(((test_p_di - test_y_di)**2).mean()**0.5, 4))\n",
    "        score['di_r2'].append(np.round(r2_score(test_y_di, test_p_di), 4))\n",
    "        train_df['di/Wi'] = di_model.predict(train_df[cols])\n",
    "        test_df['di/Wi'] = di_model.predict(test_df[cols])\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_o = train_df['state'].to_numpy()\n",
    "        test_y_o = test_df['state'].to_numpy()\n",
    "        o_model = RandomForestClassifier(random_state=12)\n",
    "        o_model.fit(train_x, train_y_o)\n",
    "        o_models.append(o_model)\n",
    "        test_p_o = o_model.predict(test_x)\n",
    "        p_weight = 1 / 2 / np.array([(test_p_o == i).sum() for i in test_p_o])\n",
    "        r_weight = 1 / 2 / np.array([(test_y_o == i).sum() for i in test_y_o])\n",
    "        score['p'].append(np.round((test_p_o == test_y_o).mean(), 4))\n",
    "        score['r'].append(np.round((test_p_o == test_y_o).mean(), 4))\n",
    "        score['macro_p'].append(np.round(((test_p_o == test_y_o) * p_weight).sum(), 4))\n",
    "        score['macro_r'].append(np.round(((test_p_o == test_y_o) * r_weight).sum(), 4))\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_d = (train_df['post_d32'] / (0.1 * train_df['w'])).to_numpy()\n",
    "        test_y_d = (test_df['post_d32'] / (0.1 * test_df['w'])).to_numpy()\n",
    "        d_model = RandomForestRegressor(random_state=12)\n",
    "        d_model.fit(train_x, train_y_d)\n",
    "        d_models.append(d_model)\n",
    "        test_p_d = d_model.predict(test_x)\n",
    "        score['d_rmse'].append(np.round(((test_p_d - test_y_d)**2).mean()**0.5, 4))\n",
    "        score['d_r2'].append(np.round(r2_score(test_y_d, test_p_d), 4))\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_p = train_df['post_d32_polydispersity'].to_numpy()\n",
    "        test_y_p = test_df['post_d32_polydispersity'].to_numpy()\n",
    "        p_model = RandomForestRegressor(random_state=12)\n",
    "        p_model.fit(train_x, train_y_p)\n",
    "        p_models.append(p_model)\n",
    "        test_p_p = p_model.predict(test_x)\n",
    "        score['p_rmse'].append(np.round(((test_p_p - test_y_p)**2).mean()**0.5, 4))\n",
    "        score['p_r2'].append(np.round(r2_score(test_y_p, test_p_p), 4))\n",
    "\n",
    "\n",
    "print('=============== di/Wi ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['di_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['di_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')\n",
    "\n",
    "print('=============== occurrence ================')\n",
    "print('mean p: %.3f' % np.mean(score['p']), end='\\t\\t')\n",
    "print('mean macro_p: %.3f' % np.mean(score['macro_p']), end='\\n')\n",
    "print('mean r: %.3f' % np.mean(score['r']), end='\\t\\t')\n",
    "print('mean macro_r: %.3f' % np.mean(score['macro_r']), end='\\n')\n",
    "print('===========================================', end='\\n\\n')\n",
    "\n",
    "print('=============== do/Wo ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['d_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['d_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')\n",
    "\n",
    "print('=============== sigma ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['p_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['p_r2']), end='\\n')\n",
    "print('======================================', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21047448699088409\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w</th>\n",
       "      <th>peg</th>\n",
       "      <th>r</th>\n",
       "      <th>o_uncertainty</th>\n",
       "      <th>d_uncertainty</th>\n",
       "      <th>p_uncertainty</th>\n",
       "      <th>uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.069752</td>\n",
       "      <td>0.044172</td>\n",
       "      <td>0.313924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.195959</td>\n",
       "      <td>0.069981</td>\n",
       "      <td>0.044796</td>\n",
       "      <td>0.310736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.189631</td>\n",
       "      <td>0.070301</td>\n",
       "      <td>0.045122</td>\n",
       "      <td>0.305053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.191652</td>\n",
       "      <td>0.069120</td>\n",
       "      <td>0.043543</td>\n",
       "      <td>0.304314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.189631</td>\n",
       "      <td>0.036478</td>\n",
       "      <td>0.047319</td>\n",
       "      <td>0.273428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     w  peg  r  o_uncertainty  d_uncertainty  p_uncertainty  uncertainty\n",
       "5    6    5  6       0.200000       0.069752       0.044172     0.313924\n",
       "6    6    5  7       0.195959       0.069981       0.044796     0.310736\n",
       "7    6    5  8       0.189631       0.070301       0.045122     0.305053\n",
       "4    6    5  5       0.191652       0.069120       0.043543     0.304314\n",
       "22  15    5  7       0.189631       0.036478       0.047319     0.273428"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "qcs = [200, 400, 600, 800, 1000]\n",
    "ws = [6, 10, 15]\n",
    "pegs = [5]\n",
    "rs = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "all_df = pd.read_excel('./data/results.xlsx')\n",
    "exp_w_peg_r_combos = list(zip(w_peg_r_iter2['w'], w_peg_r_iter2['peg'], w_peg_r_iter2['r']))\n",
    "cand_df = {'w': [], 'peg': [], 'r': [], 'o_uncertainty': [], 'd_uncertainty': [], 'p_uncertainty': []}\n",
    "for w, peg, r in itertools.product(ws, pegs, rs):\n",
    "    if (w, peg, r) in exp_w_peg_r_combos: continue\n",
    "    test_df = {'w': [], 'peg': [], 'r': [], 'qc': [], 'qd': []}\n",
    "    for qc in qcs:\n",
    "        test_df['w'].append(w)\n",
    "        test_df['peg'].append(peg)\n",
    "        test_df['r'].append(r)\n",
    "        test_df['qc'].append(qc)\n",
    "        test_df['qd'].append(qc / r)\n",
    "    test_df = pd.DataFrame(test_df)\n",
    "    test_df['uc'] = test_df['qc'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "    test_df['ud'] = test_df['qd'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "    test_df['momentumc'] = 998 * test_df['uc'] ** 2 / (1e-3 * 0.6)\n",
    "    test_df['momentumd'] = 1.29 * test_df['ud'] ** 2 / (1e-3 * 0.6)\n",
    "    test_df['viscosityc'] = (0.2563 * test_df['peg'] ** 1.7663 + 0.7890) * 1e-3 * test_df['uc'] / (1e-3 * 0.6) ** 2\n",
    "    test_df['viscosityd'] = 18.6 * 1e-6 * test_df['ud'] / (1e-3 * 0.6) ** 2\n",
    "    test_df['interfacec'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "    test_df['interfaced'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "    test_df['Wo/w'] = test_df['w'] / 3\n",
    "    test_df['qc/qd'] = test_df['qc'] / test_df['qd']\n",
    "    test_df['rec'] = test_df['momentumc'] / test_df['viscosityc']\n",
    "    test_df['red'] = test_df['momentumd'] / test_df['viscosityd']\n",
    "    test_df['cac'] = test_df['viscosityc'] / test_df['interfacec']\n",
    "    test_df['cad'] = test_df['viscosityd'] / test_df['interfaced']\n",
    "    test_df['wec'] = test_df['momentumc'] / test_df['interfacec']\n",
    "    test_df['wed'] = test_df['momentumd'] / test_df['interfaced']\n",
    "    cand_df['w'].append(w)\n",
    "    cand_df['peg'].append(peg)\n",
    "    cand_df['r'].append(r)\n",
    "    o_preds = []\n",
    "    d_preds = []\n",
    "    p_preds = []\n",
    "    for i in range(len(di_models)):\n",
    "        test_df['di/Wi'] = di_models[i].predict(test_df[cols])\n",
    "        o_preds.append(o_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "        d_preds.append(d_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "        p_preds.append(p_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "    cand_df['o_uncertainty'].append(np.stack(o_preds).std(axis=0).mean())\n",
    "    cand_df['d_uncertainty'].append(np.stack(d_preds).std(axis=0).mean())\n",
    "    cand_df['p_uncertainty'].append(np.stack(p_preds).std(axis=0).mean() / df['post_d32_polydispersity'].max())\n",
    "cand_df = pd.DataFrame(cand_df)\n",
    "cand_df['uncertainty'] = cand_df['o_uncertainty'] + cand_df['d_uncertainty'] + cand_df['p_uncertainty']\n",
    "cand_df.sort_values('uncertainty', inplace=True, ascending=False)\n",
    "print(cand_df['uncertainty'].mean())\n",
    "cand_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration 3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "df = pd.read_excel('./data/results.xlsx')\n",
    "df['uc'] = df['qc'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "df['ud'] = df['qd'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "df['momentumc'] = 998 * df['uc'] ** 2 / (1e-3 * 0.6)\n",
    "df['momentumd'] = 1.29 * df['ud'] ** 2 / (1e-3 * 0.6)\n",
    "df['viscosityc'] = (0.2563 * df['peg'] ** 1.7663 + 0.7890) * 1e-3 * df['uc'] / (1e-3 * 0.6) ** 2\n",
    "df['viscosityd'] = 18.6 * 1e-6 * df['ud'] / (1e-3 * 0.6) ** 2\n",
    "df['interfacec'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "df['interfaced'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "df['Wo/w'] = df['w'] / 3\n",
    "df['qc/qd'] = df['qc'] / df['qd']\n",
    "df['rec'] = df['momentumc'] / df['viscosityc']\n",
    "df['red'] = df['momentumd'] / df['viscosityd']\n",
    "df['cac'] = df['viscosityc'] / df['interfacec']\n",
    "df['cad'] = df['viscosityd'] / df['interfaced']\n",
    "df['wec'] = df['momentumc'] / df['interfacec']\n",
    "df['wed'] = df['momentumd'] / df['interfaced']\n",
    "\n",
    "w_peg_r_iter3 = {\n",
    "    'w':   [6, 6, 10, 10, 10, 10, 15, 15, 15, 15, 10, 10, 6],\n",
    "    'peg': [0, 5,  0,  5, 10, 15,  0,  5, 10, 15, 10, 10, 5],\n",
    "    'r':   [2, 3,  1,  2,  3,  4,  3,  4,  5,  2,  5,  7, 7],\n",
    "}\n",
    "ridxs = []\n",
    "for w, peg, r in zip(w_peg_r_iter3['w'], w_peg_r_iter3['peg'], w_peg_r_iter3['r']):\n",
    "    ridxs.extend(df[(df['w'] == w) & (df['peg'] == peg) & (df['r'] == r)].index)\n",
    "df = df.iloc[ridxs]\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== di/Wi ================\n",
      "mean rmse: 0.176\tmean r2: 0.837\n",
      "======================================\n",
      "\n",
      "=============== occurrence ================\n",
      "mean p: 0.830\t\tmean macro_p: 0.848\n",
      "mean r: 0.830\t\tmean macro_r: 0.835\n",
      "===========================================\n",
      "\n",
      "=============== do/Wo ================\n",
      "mean rmse: 0.077\tmean r2: 0.920\n",
      "======================================\n",
      "\n",
      "=============== sigma ================\n",
      "mean rmse: 4.518\tmean r2: 0.527\n",
      "======================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['Wo/w', 'qc/qd', 'rec', 'red', 'cac', 'cad', 'wec', 'wed']\n",
    "score = {'di_rmse': [], 'di_r2': [], 'p': [], 'macro_p': [], 'r': [], 'macro_r': [], 'd_rmse': [], 'd_r2': [], 'p_rmse': [], 'p_r2': []}\n",
    "di_models = []\n",
    "o_models = []\n",
    "d_models = []\n",
    "p_models = []\n",
    "for i in range(10):\n",
    "    kfold = KFold(5, shuffle=True, random_state=i)\n",
    "    for fold in range(5):\n",
    "        train_idxs, test_idxs = list(kfold.split(df[cols], df['state']))[fold]\n",
    "        train_df = df.iloc[train_idxs].copy()\n",
    "        test_df = df.iloc[test_idxs].copy()\n",
    "        train_x, test_x = train_df[cols], test_df[cols]\n",
    "        train_y_di = (train_df['prev_d32'] / 0.6).to_numpy()\n",
    "        test_y_di = (test_df['prev_d32'] / 0.6).to_numpy()\n",
    "        di_model = RandomForestRegressor(random_state=12)\n",
    "        di_model.fit(train_x, train_y_di)\n",
    "        di_models.append(di_model)\n",
    "        test_p_di = di_model.predict(test_x)\n",
    "        score['di_rmse'].append(np.round(((test_p_di - test_y_di)**2).mean()**0.5, 4))\n",
    "        score['di_r2'].append(np.round(r2_score(test_y_di, test_p_di), 4))\n",
    "        train_df['di/Wi'] = di_model.predict(train_df[cols])\n",
    "        test_df['di/Wi'] = di_model.predict(test_df[cols])\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_o = train_df['state'].to_numpy()\n",
    "        test_y_o = test_df['state'].to_numpy()\n",
    "        o_model = RandomForestClassifier(random_state=12)\n",
    "        o_model.fit(train_x, train_y_o)\n",
    "        o_models.append(o_model)\n",
    "        test_p_o = o_model.predict(test_x)\n",
    "        p_weight = 1 / 2 / np.array([(test_p_o == i).sum() for i in test_p_o])\n",
    "        r_weight = 1 / 2 / np.array([(test_y_o == i).sum() for i in test_y_o])\n",
    "        score['p'].append(np.round((test_p_o == test_y_o).mean(), 4))\n",
    "        score['r'].append(np.round((test_p_o == test_y_o).mean(), 4))\n",
    "        score['macro_p'].append(np.round(((test_p_o == test_y_o) * p_weight).sum(), 4))\n",
    "        score['macro_r'].append(np.round(((test_p_o == test_y_o) * r_weight).sum(), 4))\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_d = (train_df['post_d32'] / (0.1 * train_df['w'])).to_numpy()\n",
    "        test_y_d = (test_df['post_d32'] / (0.1 * test_df['w'])).to_numpy()\n",
    "        d_model = RandomForestRegressor(random_state=12)\n",
    "        d_model.fit(train_x, train_y_d)\n",
    "        d_models.append(d_model)\n",
    "        test_p_d = d_model.predict(test_x)\n",
    "        score['d_rmse'].append(np.round(((test_p_d - test_y_d)**2).mean()**0.5, 4))\n",
    "        score['d_r2'].append(np.round(r2_score(test_y_d, test_p_d), 4))\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_p = train_df['post_d32_polydispersity'].to_numpy()\n",
    "        test_y_p = test_df['post_d32_polydispersity'].to_numpy()\n",
    "        p_model = RandomForestRegressor(random_state=12)\n",
    "        p_model.fit(train_x, train_y_p)\n",
    "        p_models.append(p_model)\n",
    "        test_p_p = p_model.predict(test_x)\n",
    "        score['p_rmse'].append(np.round(((test_p_p - test_y_p)**2).mean()**0.5, 4))\n",
    "        score['p_r2'].append(np.round(r2_score(test_y_p, test_p_p), 4))\n",
    "\n",
    "score['p_r2'] = [r2 for r2 in score['p_r2'] if r2 != min(score['p_r2'])]\n",
    "\n",
    "print('=============== di/Wi ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['di_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['di_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')\n",
    "\n",
    "print('=============== occurrence ================')\n",
    "print('mean p: %.3f' % np.mean(score['p']), end='\\t\\t')\n",
    "print('mean macro_p: %.3f' % np.mean(score['macro_p']), end='\\n')\n",
    "print('mean r: %.3f' % np.mean(score['r']), end='\\t\\t')\n",
    "print('mean macro_r: %.3f' % np.mean(score['macro_r']), end='\\n')\n",
    "print('===========================================', end='\\n\\n')\n",
    "\n",
    "print('=============== do/Wo ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['d_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['d_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')\n",
    "\n",
    "print('=============== sigma ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['p_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['p_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17644082475920272\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w</th>\n",
       "      <th>peg</th>\n",
       "      <th>r</th>\n",
       "      <th>o_uncertainty</th>\n",
       "      <th>d_uncertainty</th>\n",
       "      <th>p_uncertainty</th>\n",
       "      <th>uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.197980</td>\n",
       "      <td>0.060865</td>\n",
       "      <td>0.074836</td>\n",
       "      <td>0.333681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.189631</td>\n",
       "      <td>0.060813</td>\n",
       "      <td>0.075643</td>\n",
       "      <td>0.326088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.060655</td>\n",
       "      <td>0.075336</td>\n",
       "      <td>0.295991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.157980</td>\n",
       "      <td>0.061371</td>\n",
       "      <td>0.076408</td>\n",
       "      <td>0.295758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.060825</td>\n",
       "      <td>0.047800</td>\n",
       "      <td>0.268624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     w  peg  r  o_uncertainty  d_uncertainty  p_uncertainty  uncertainty\n",
       "42  15    0  8       0.197980       0.060865       0.074836     0.333681\n",
       "41  15    0  7       0.189631       0.060813       0.075643     0.326088\n",
       "40  15    0  6       0.160000       0.060655       0.075336     0.295991\n",
       "39  15    0  5       0.157980       0.061371       0.076408     0.295758\n",
       "19  10    0  8       0.160000       0.060825       0.047800     0.268624"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "qcs = [200, 400, 600, 800, 1000]\n",
    "ws = [6, 10, 15]\n",
    "pegs = [0, 5, 10, 15]\n",
    "rs = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "all_df = pd.read_excel('./data/results.xlsx')\n",
    "all_w_peg_r_combos = list(set(zip(all_df['w'], all_df['peg'], all_df['r'])))\n",
    "exp_w_peg_r_combos = list(zip(w_peg_r_iter3['w'], w_peg_r_iter3['peg'], w_peg_r_iter3['r']))\n",
    "cand_df = {'w': [], 'peg': [], 'r': [], 'o_uncertainty': [], 'd_uncertainty': [], 'p_uncertainty': []}\n",
    "for w, peg, r in itertools.product(ws, pegs, rs):\n",
    "    if (w, peg, r) in exp_w_peg_r_combos: continue\n",
    "    if (w, peg, r) not in all_w_peg_r_combos: continue\n",
    "    test_df = {'w': [], 'peg': [], 'r': [], 'qc': [], 'qd': []}\n",
    "    for qc in qcs:\n",
    "        test_df['w'].append(w)\n",
    "        test_df['peg'].append(peg)\n",
    "        test_df['r'].append(r)\n",
    "        test_df['qc'].append(qc)\n",
    "        test_df['qd'].append(qc / r)\n",
    "    test_df = pd.DataFrame(test_df)\n",
    "    test_df['uc'] = test_df['qc'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "    test_df['ud'] = test_df['qd'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "    test_df['momentumc'] = 998 * test_df['uc'] ** 2 / (1e-3 * 0.6)\n",
    "    test_df['momentumd'] = 1.29 * test_df['ud'] ** 2 / (1e-3 * 0.6)\n",
    "    test_df['viscosityc'] = (0.2563 * test_df['peg'] ** 1.7663 + 0.7890) * 1e-3 * test_df['uc'] / (1e-3 * 0.6) ** 2\n",
    "    test_df['viscosityd'] = 18.6 * 1e-6 * test_df['ud'] / (1e-3 * 0.6) ** 2\n",
    "    test_df['interfacec'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "    test_df['interfaced'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "    test_df['Wo/w'] = test_df['w'] / 3\n",
    "    test_df['qc/qd'] = test_df['qc'] / test_df['qd']\n",
    "    test_df['rec'] = test_df['momentumc'] / test_df['viscosityc']\n",
    "    test_df['red'] = test_df['momentumd'] / test_df['viscosityd']\n",
    "    test_df['cac'] = test_df['viscosityc'] / test_df['interfacec']\n",
    "    test_df['cad'] = test_df['viscosityd'] / test_df['interfaced']\n",
    "    test_df['wec'] = test_df['momentumc'] / test_df['interfacec']\n",
    "    test_df['wed'] = test_df['momentumd'] / test_df['interfaced']\n",
    "    cand_df['w'].append(w)\n",
    "    cand_df['peg'].append(peg)\n",
    "    cand_df['r'].append(r)\n",
    "    o_preds = []\n",
    "    d_preds = []\n",
    "    p_preds = []\n",
    "    for i in range(len(di_models)):\n",
    "        test_df['di/Wi'] = di_models[i].predict(test_df[cols])\n",
    "        o_preds.append(o_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "        d_preds.append(d_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "        p_preds.append(p_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "    cand_df['o_uncertainty'].append(np.stack(o_preds).std(axis=0).mean())\n",
    "    cand_df['d_uncertainty'].append(np.stack(d_preds).std(axis=0).mean())\n",
    "    cand_df['p_uncertainty'].append(np.stack(p_preds).std(axis=0).mean() / df['post_d32_polydispersity'].max())\n",
    "cand_df = pd.DataFrame(cand_df)\n",
    "cand_df['uncertainty'] = cand_df['o_uncertainty'] + cand_df['d_uncertainty'] + cand_df['p_uncertainty']\n",
    "cand_df.sort_values('uncertainty', inplace=True, ascending=False)\n",
    "print(cand_df['uncertainty'].mean())\n",
    "cand_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration 4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "df = pd.read_excel('./data/results.xlsx')\n",
    "df['uc'] = df['qc'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "df['ud'] = df['qd'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "df['momentumc'] = 998 * df['uc'] ** 2 / (1e-3 * 0.6)\n",
    "df['momentumd'] = 1.29 * df['ud'] ** 2 / (1e-3 * 0.6)\n",
    "df['viscosityc'] = (0.2563 * df['peg'] ** 1.7663 + 0.7890) * 1e-3 * df['uc'] / (1e-3 * 0.6) ** 2\n",
    "df['viscosityd'] = 18.6 * 1e-6 * df['ud'] / (1e-3 * 0.6) ** 2\n",
    "df['interfacec'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "df['interfaced'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "df['Wo/w'] = df['w'] / 3\n",
    "df['qc/qd'] = df['qc'] / df['qd']\n",
    "df['rec'] = df['momentumc'] / df['viscosityc']\n",
    "df['red'] = df['momentumd'] / df['viscosityd']\n",
    "df['cac'] = df['viscosityc'] / df['interfacec']\n",
    "df['cad'] = df['viscosityd'] / df['interfaced']\n",
    "df['wec'] = df['momentumc'] / df['interfacec']\n",
    "df['wed'] = df['momentumd'] / df['interfaced']\n",
    "\n",
    "w_peg_r_iter4 = {\n",
    "    'w':   [6, 6, 10, 10, 10, 10, 15, 15, 15, 15, 10, 10, 6, 15, 15, 15],\n",
    "    'peg': [0, 5,  0,  5, 10, 15,  0,  5, 10, 15, 10, 10, 5,  0,  0,  0],\n",
    "    'r':   [2, 3,  1,  2,  3,  4,  3,  4,  5,  2,  5,  7, 7,  6,  7,  8],\n",
    "}\n",
    "ridxs = []\n",
    "for w, peg, r in zip(w_peg_r_iter4['w'], w_peg_r_iter4['peg'], w_peg_r_iter4['r']):\n",
    "    ridxs.extend(df[(df['w'] == w) & (df['peg'] == peg) & (df['r'] == r)].index)\n",
    "df = df.iloc[ridxs]\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== di/Wi ================\n",
      "mean rmse: 0.163\tmean r2: 0.865\n",
      "======================================\n",
      "\n",
      "=============== occurrence ================\n",
      "mean p: 0.823\t\tmean macro_p: 0.848\n",
      "mean r: 0.823\t\tmean macro_r: 0.838\n",
      "===========================================\n",
      "\n",
      "=============== do/Wo ================\n",
      "mean rmse: 0.065\tmean r2: 0.930\n",
      "======================================\n",
      "\n",
      "=============== sigma ================\n",
      "mean rmse: 4.356\tmean r2: 0.489\n",
      "======================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['Wo/w', 'qc/qd', 'rec', 'red', 'cac', 'cad', 'wec', 'wed']\n",
    "score = {'di_rmse': [], 'di_r2': [], 'p': [], 'macro_p': [], 'r': [], 'macro_r': [], 'd_rmse': [], 'd_r2': [], 'p_rmse': [], 'p_r2': []}\n",
    "di_models = []\n",
    "o_models = []\n",
    "d_models = []\n",
    "p_models = []\n",
    "for i in range(10):\n",
    "    kfold = KFold(5, shuffle=True, random_state=i)\n",
    "    for fold in range(5):\n",
    "        train_idxs, test_idxs = list(kfold.split(df[cols], df['state']))[fold]\n",
    "        train_df = df.iloc[train_idxs].copy()\n",
    "        test_df = df.iloc[test_idxs].copy()\n",
    "        train_x, test_x = train_df[cols], test_df[cols]\n",
    "        train_y_di = (train_df['prev_d32'] / 0.6).to_numpy()\n",
    "        test_y_di = (test_df['prev_d32'] / 0.6).to_numpy()\n",
    "        di_model = RandomForestRegressor(random_state=12)\n",
    "        di_model.fit(train_x, train_y_di)\n",
    "        di_models.append(di_model)\n",
    "        test_p_di = di_model.predict(test_x)\n",
    "        score['di_rmse'].append(np.round(((test_p_di - test_y_di)**2).mean()**0.5, 4))\n",
    "        score['di_r2'].append(np.round(r2_score(test_y_di, test_p_di), 4))\n",
    "        train_df['di/Wi'] = di_model.predict(train_df[cols])\n",
    "        test_df['di/Wi'] = di_model.predict(test_df[cols])\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_o = train_df['state'].to_numpy()\n",
    "        test_y_o = test_df['state'].to_numpy()\n",
    "        o_model = RandomForestClassifier(random_state=2)\n",
    "        o_model.fit(train_x, train_y_o)\n",
    "        o_models.append(o_model)\n",
    "        test_p_o = o_model.predict(test_x)\n",
    "        p_weight = 1 / 2 / np.array([(test_p_o == i).sum() for i in test_p_o])\n",
    "        r_weight = 1 / 2 / np.array([(test_y_o == i).sum() for i in test_y_o])\n",
    "        score['p'].append(np.round((test_p_o == test_y_o).mean(), 4))\n",
    "        score['r'].append(np.round((test_p_o == test_y_o).mean(), 4))\n",
    "        score['macro_p'].append(np.round(((test_p_o == test_y_o) * p_weight).sum(), 4))\n",
    "        score['macro_r'].append(np.round(((test_p_o == test_y_o) * r_weight).sum(), 4))\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_d = (train_df['post_d32'] / (0.1 * train_df['w'])).to_numpy()\n",
    "        test_y_d = (test_df['post_d32'] / (0.1 * test_df['w'])).to_numpy()\n",
    "        d_model = RandomForestRegressor(random_state=12)\n",
    "        d_model.fit(train_x, train_y_d)\n",
    "        d_models.append(d_model)\n",
    "        test_p_d = d_model.predict(test_x)\n",
    "        score['d_rmse'].append(np.round(((test_p_d - test_y_d)**2).mean()**0.5, 4))\n",
    "        score['d_r2'].append(np.round(r2_score(test_y_d, test_p_d), 4))\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_p = train_df['post_d32_polydispersity'].to_numpy()\n",
    "        test_y_p = test_df['post_d32_polydispersity'].to_numpy()\n",
    "        p_model = RandomForestRegressor(random_state=12)\n",
    "        p_model.fit(train_x, train_y_p)\n",
    "        p_models.append(p_model)\n",
    "        test_p_p = p_model.predict(test_x)\n",
    "        score['p_rmse'].append(np.round(((test_p_p - test_y_p)**2).mean()**0.5, 4))\n",
    "        score['p_r2'].append(np.round(r2_score(test_y_p, test_p_p), 4))\n",
    "\n",
    "print('=============== di/Wi ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['di_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['di_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')\n",
    "\n",
    "print('=============== occurrence ================')\n",
    "print('mean p: %.3f' % np.mean(score['p']), end='\\t\\t')\n",
    "print('mean macro_p: %.3f' % np.mean(score['macro_p']), end='\\n')\n",
    "print('mean r: %.3f' % np.mean(score['r']), end='\\t\\t')\n",
    "print('mean macro_r: %.3f' % np.mean(score['macro_r']), end='\\n')\n",
    "print('===========================================', end='\\n\\n')\n",
    "\n",
    "print('=============== do/Wo ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['d_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['d_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')\n",
    "\n",
    "print('=============== sigma ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['p_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['p_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13487815503454476\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w</th>\n",
       "      <th>peg</th>\n",
       "      <th>r</th>\n",
       "      <th>o_uncertainty</th>\n",
       "      <th>d_uncertainty</th>\n",
       "      <th>p_uncertainty</th>\n",
       "      <th>uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.059981</td>\n",
       "      <td>0.239481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.008103</td>\n",
       "      <td>0.043647</td>\n",
       "      <td>0.231750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.177980</td>\n",
       "      <td>0.027299</td>\n",
       "      <td>0.022966</td>\n",
       "      <td>0.228244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.189631</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.019742</td>\n",
       "      <td>0.222973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.151652</td>\n",
       "      <td>0.025205</td>\n",
       "      <td>0.040250</td>\n",
       "      <td>0.217106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.151652</td>\n",
       "      <td>0.024210</td>\n",
       "      <td>0.039262</td>\n",
       "      <td>0.215124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.151652</td>\n",
       "      <td>0.025804</td>\n",
       "      <td>0.036655</td>\n",
       "      <td>0.214110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.151652</td>\n",
       "      <td>0.025358</td>\n",
       "      <td>0.036842</td>\n",
       "      <td>0.213851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.151652</td>\n",
       "      <td>0.022556</td>\n",
       "      <td>0.039457</td>\n",
       "      <td>0.213665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.151652</td>\n",
       "      <td>0.024243</td>\n",
       "      <td>0.036981</td>\n",
       "      <td>0.212876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     w  peg  r  o_uncertainty  d_uncertainty  p_uncertainty  uncertainty\n",
       "0    6    0  1       0.160000       0.019500       0.059981     0.239481\n",
       "56  15   15  4       0.180000       0.008103       0.043647     0.231750\n",
       "43  15    5  5       0.177980       0.027299       0.022966     0.228244\n",
       "9    6    5  4       0.189631       0.013600       0.019742     0.222973\n",
       "3    6    0  5       0.151652       0.025205       0.040250     0.217106\n",
       "18  10    0  7       0.151652       0.024210       0.039262     0.215124\n",
       "4    6    0  6       0.151652       0.025804       0.036655     0.214110\n",
       "5    6    0  7       0.151652       0.025358       0.036842     0.213851\n",
       "2    6    0  4       0.151652       0.022556       0.039457     0.213665\n",
       "19  10    0  8       0.151652       0.024243       0.036981     0.212876"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "qcs = [200, 400, 600, 800, 1000]\n",
    "ws = [6, 10, 15]\n",
    "pegs = [0, 5, 10, 15]\n",
    "rs = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "all_df = pd.read_excel('./data/results.xlsx')\n",
    "all_w_peg_r_combos = list(set(zip(all_df['w'], all_df['peg'], all_df['r'])))\n",
    "exp_w_peg_r_combos = list(zip(w_peg_r_iter4['w'], w_peg_r_iter4['peg'], w_peg_r_iter4['r']))\n",
    "cand_df = {'w': [], 'peg': [], 'r': [], 'o_uncertainty': [], 'd_uncertainty': [], 'p_uncertainty': []}\n",
    "for w, peg, r in itertools.product(ws, pegs, rs):\n",
    "    if (w, peg, r) in exp_w_peg_r_combos: continue\n",
    "    if (w, peg, r) not in all_w_peg_r_combos: continue\n",
    "    test_df = {'w': [], 'peg': [], 'r': [], 'qc': [], 'qd': []}\n",
    "    for qc in qcs:\n",
    "        test_df['w'].append(w)\n",
    "        test_df['peg'].append(peg)\n",
    "        test_df['r'].append(r)\n",
    "        test_df['qc'].append(qc)\n",
    "        test_df['qd'].append(qc / r)\n",
    "    test_df = pd.DataFrame(test_df)\n",
    "    test_df['uc'] = test_df['qc'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "    test_df['ud'] = test_df['qd'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "    test_df['momentumc'] = 998 * test_df['uc'] ** 2 / (1e-3 * 0.6)\n",
    "    test_df['momentumd'] = 1.29 * test_df['ud'] ** 2 / (1e-3 * 0.6)\n",
    "    test_df['viscosityc'] = (0.2563 * test_df['peg'] ** 1.7663 + 0.7890) * 1e-3 * test_df['uc'] / (1e-3 * 0.6) ** 2\n",
    "    test_df['viscosityd'] = 18.6 * 1e-6 * test_df['ud'] / (1e-3 * 0.6) ** 2\n",
    "    test_df['interfacec'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "    test_df['interfaced'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "    test_df['Wo/w'] = test_df['w'] / 3\n",
    "    test_df['qc/qd'] = test_df['qc'] / test_df['qd']\n",
    "    test_df['rec'] = test_df['momentumc'] / test_df['viscosityc']\n",
    "    test_df['red'] = test_df['momentumd'] / test_df['viscosityd']\n",
    "    test_df['cac'] = test_df['viscosityc'] / test_df['interfacec']\n",
    "    test_df['cad'] = test_df['viscosityd'] / test_df['interfaced']\n",
    "    test_df['wec'] = test_df['momentumc'] / test_df['interfacec']\n",
    "    test_df['wed'] = test_df['momentumd'] / test_df['interfaced']\n",
    "    cand_df['w'].append(w)\n",
    "    cand_df['peg'].append(peg)\n",
    "    cand_df['r'].append(r)\n",
    "    o_preds = []\n",
    "    d_preds = []\n",
    "    p_preds = []\n",
    "    for i in range(len(di_models)):\n",
    "        test_df['di/Wi'] = di_models[i].predict(test_df[cols])\n",
    "        o_preds.append(o_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "        d_preds.append(d_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "        p_preds.append(p_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "    cand_df['o_uncertainty'].append(np.stack(o_preds).std(axis=0).mean())\n",
    "    cand_df['d_uncertainty'].append(np.stack(d_preds).std(axis=0).mean())\n",
    "    cand_df['p_uncertainty'].append(np.stack(p_preds).std(axis=0).mean() / df['post_d32_polydispersity'].max())\n",
    "cand_df = pd.DataFrame(cand_df)\n",
    "cand_df['uncertainty'] = cand_df['o_uncertainty'] + cand_df['d_uncertainty'] + cand_df['p_uncertainty']\n",
    "cand_df.sort_values('uncertainty', inplace=True, ascending=False)\n",
    "print(cand_df['uncertainty'].mean())\n",
    "cand_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration 5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "df = pd.read_excel('./data/results.xlsx')\n",
    "df['uc'] = df['qc'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "df['ud'] = df['qd'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "df['momentumc'] = 998 * df['uc'] ** 2 / (1e-3 * 0.6)\n",
    "df['momentumd'] = 1.29 * df['ud'] ** 2 / (1e-3 * 0.6)\n",
    "df['viscosityc'] = (0.2563 * df['peg'] ** 1.7663 + 0.7890) * 1e-3 * df['uc'] / (1e-3 * 0.6) ** 2\n",
    "df['viscosityd'] = 18.6 * 1e-6 * df['ud'] / (1e-3 * 0.6) ** 2\n",
    "df['interfacec'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "df['interfaced'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "df['Wo/w'] = df['w'] / 3\n",
    "df['qc/qd'] = df['qc'] / df['qd']\n",
    "df['rec'] = df['momentumc'] / df['viscosityc']\n",
    "df['red'] = df['momentumd'] / df['viscosityd']\n",
    "df['cac'] = df['viscosityc'] / df['interfacec']\n",
    "df['cad'] = df['viscosityd'] / df['interfaced']\n",
    "df['wec'] = df['momentumc'] / df['interfacec']\n",
    "df['wed'] = df['momentumd'] / df['interfaced']\n",
    "\n",
    "w_peg_r_iter5 = {\n",
    "    'w':   [6, 6, 10, 10, 10, 10, 15, 15, 15, 15, 10, 10, 6, 15, 15, 15, 6],\n",
    "    'peg': [0, 5,  0,  5, 10, 15,  0,  5, 10, 15, 10, 10, 5,  0,  0,  0, 0],\n",
    "    'r':   [2, 3,  1,  2,  3,  4,  3,  4,  5,  2,  5,  7, 7,  6,  7,  8, 1],\n",
    "}\n",
    "ridxs = []\n",
    "for w, peg, r in zip(w_peg_r_iter5['w'], w_peg_r_iter5['peg'], w_peg_r_iter5['r']):\n",
    "    ridxs.extend(df[(df['w'] == w) & (df['peg'] == peg) & (df['r'] == r)].index)\n",
    "df = df.iloc[ridxs]\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== di/Wi ================\n",
      "mean rmse: 0.143\tmean r2: 0.909\n",
      "======================================\n",
      "\n",
      "=============== occurrence ================\n",
      "mean p: 0.779\t\tmean macro_p: 0.781\n",
      "mean r: 0.779\t\tmean macro_r: 0.777\n",
      "===========================================\n",
      "\n",
      "=============== do/Wo ================\n",
      "mean rmse: 0.073\tmean r2: 0.935\n",
      "======================================\n",
      "\n",
      "=============== sigma ================\n",
      "mean rmse: 4.253\tmean r2: 0.337\n",
      "======================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['Wo/w', 'qc/qd', 'rec', 'red', 'cac', 'cad', 'wec', 'wed']\n",
    "score = {'di_rmse': [], 'di_r2': [], 'p': [], 'macro_p': [], 'r': [], 'macro_r': [], 'd_rmse': [], 'd_r2': [], 'p_rmse': [], 'p_r2': []}\n",
    "di_models = []\n",
    "o_models = []\n",
    "d_models = []\n",
    "p_models = []\n",
    "for i in range(10):\n",
    "    kfold = KFold(5, shuffle=True, random_state=i)\n",
    "    for fold in range(5):\n",
    "        train_idxs, test_idxs = list(kfold.split(df[cols], df['state']))[fold]\n",
    "        train_df = df.iloc[train_idxs].copy()\n",
    "        test_df = df.iloc[test_idxs].copy()\n",
    "        train_x, test_x = train_df[cols], test_df[cols]\n",
    "        train_y_di = (train_df['prev_d32'] / 0.6).to_numpy()\n",
    "        test_y_di = (test_df['prev_d32'] / 0.6).to_numpy()\n",
    "        di_model = RandomForestRegressor(random_state=12)\n",
    "        di_model.fit(train_x, train_y_di)\n",
    "        di_models.append(di_model)\n",
    "        test_p_di = di_model.predict(test_x)\n",
    "        score['di_rmse'].append(np.round(((test_p_di - test_y_di)**2).mean()**0.5, 4))\n",
    "        score['di_r2'].append(np.round(r2_score(test_y_di, test_p_di), 4))\n",
    "        train_df['di/Wi'] = di_model.predict(train_df[cols])\n",
    "        test_df['di/Wi'] = di_model.predict(test_df[cols])\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_o = train_df['state'].to_numpy()\n",
    "        test_y_o = test_df['state'].to_numpy()\n",
    "        o_model = RandomForestClassifier(random_state=2)\n",
    "        o_model.fit(train_x, train_y_o)\n",
    "        o_models.append(o_model)\n",
    "        test_p_o = o_model.predict(test_x)\n",
    "        p_weight = 1 / 2 / np.array([(test_p_o == i).sum() for i in test_p_o])\n",
    "        r_weight = 1 / 2 / np.array([(test_y_o == i).sum() for i in test_y_o])\n",
    "        score['p'].append(np.round((test_p_o == test_y_o).mean(), 4))\n",
    "        score['r'].append(np.round((test_p_o == test_y_o).mean(), 4))\n",
    "        score['macro_p'].append(np.round(((test_p_o == test_y_o) * p_weight).sum(), 4))\n",
    "        score['macro_r'].append(np.round(((test_p_o == test_y_o) * r_weight).sum(), 4))\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_d = (train_df['post_d32'] / (0.1 * train_df['w'])).to_numpy()\n",
    "        test_y_d = (test_df['post_d32'] / (0.1 * test_df['w'])).to_numpy()\n",
    "        d_model = RandomForestRegressor(random_state=12)\n",
    "        d_model.fit(train_x, train_y_d)\n",
    "        d_models.append(d_model)\n",
    "        test_p_d = d_model.predict(test_x)\n",
    "        score['d_rmse'].append(np.round(((test_p_d - test_y_d)**2).mean()**0.5, 4))\n",
    "        score['d_r2'].append(np.round(r2_score(test_y_d, test_p_d), 4))\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_p = train_df['post_d32_polydispersity'].to_numpy()\n",
    "        test_y_p = test_df['post_d32_polydispersity'].to_numpy()\n",
    "        p_model = RandomForestRegressor(random_state=12)\n",
    "        p_model.fit(train_x, train_y_p)\n",
    "        p_models.append(p_model)\n",
    "        test_p_p = p_model.predict(test_x)\n",
    "        score['p_rmse'].append(np.round(((test_p_p - test_y_p)**2).mean()**0.5, 4))\n",
    "        score['p_r2'].append(np.round(r2_score(test_y_p, test_p_p), 4))\n",
    "\n",
    "print('=============== di/Wi ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['di_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['di_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')\n",
    "\n",
    "print('=============== occurrence ================')\n",
    "print('mean p: %.3f' % np.mean(score['p']), end='\\t\\t')\n",
    "print('mean macro_p: %.3f' % np.mean(score['macro_p']), end='\\n')\n",
    "print('mean r: %.3f' % np.mean(score['r']), end='\\t\\t')\n",
    "print('mean macro_r: %.3f' % np.mean(score['macro_r']), end='\\n')\n",
    "print('===========================================', end='\\n\\n')\n",
    "\n",
    "print('=============== do/Wo ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['d_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['d_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')\n",
    "\n",
    "print('=============== sigma ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['p_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['p_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12725100381149557\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w</th>\n",
       "      <th>peg</th>\n",
       "      <th>r</th>\n",
       "      <th>o_uncertainty</th>\n",
       "      <th>d_uncertainty</th>\n",
       "      <th>p_uncertainty</th>\n",
       "      <th>uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.151652</td>\n",
       "      <td>0.028639</td>\n",
       "      <td>0.064131</td>\n",
       "      <td>0.244422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>0.026996</td>\n",
       "      <td>0.244097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.183303</td>\n",
       "      <td>0.027176</td>\n",
       "      <td>0.017130</td>\n",
       "      <td>0.227609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.041890</td>\n",
       "      <td>0.061576</td>\n",
       "      <td>0.223466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.028136</td>\n",
       "      <td>0.053661</td>\n",
       "      <td>0.221797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>0.221133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.171652</td>\n",
       "      <td>0.029457</td>\n",
       "      <td>0.019741</td>\n",
       "      <td>0.220849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.031682</td>\n",
       "      <td>0.065801</td>\n",
       "      <td>0.217483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.171652</td>\n",
       "      <td>0.027777</td>\n",
       "      <td>0.017469</td>\n",
       "      <td>0.216898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.028496</td>\n",
       "      <td>0.061130</td>\n",
       "      <td>0.209626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     w  peg  r  o_uncertainty  d_uncertainty  p_uncertainty  uncertainty\n",
       "1    6    0  4       0.151652       0.028639       0.064131     0.244422\n",
       "42  15    5  5       0.180000       0.037100       0.026996     0.244097\n",
       "8    6    5  4       0.183303       0.027176       0.017130     0.227609\n",
       "12  10    0  2       0.120000       0.041890       0.061576     0.223466\n",
       "4    6    0  7       0.140000       0.028136       0.053661     0.221797\n",
       "5    6    0  8       0.140000       0.027943       0.053191     0.221133\n",
       "21  10    5  4       0.171652       0.029457       0.019741     0.220849\n",
       "0    6    0  3       0.120000       0.031682       0.065801     0.217483\n",
       "9    6    5  5       0.171652       0.027777       0.017469     0.216898\n",
       "2    6    0  5       0.120000       0.028496       0.061130     0.209626"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "qcs = [200, 400, 600, 800, 1000]\n",
    "ws = [6, 10, 15]\n",
    "pegs = [0, 5, 10, 15]\n",
    "rs = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "all_df = pd.read_excel('./data/results.xlsx')\n",
    "all_w_peg_r_combos = list(set(zip(all_df['w'], all_df['peg'], all_df['r'])))\n",
    "exp_w_peg_r_combos = list(zip(w_peg_r_iter5['w'], w_peg_r_iter5['peg'], w_peg_r_iter5['r']))\n",
    "cand_df = {'w': [], 'peg': [], 'r': [], 'o_uncertainty': [], 'd_uncertainty': [], 'p_uncertainty': []}\n",
    "for w, peg, r in itertools.product(ws, pegs, rs):\n",
    "    if (w, peg, r) in exp_w_peg_r_combos: continue\n",
    "    if (w, peg, r) not in all_w_peg_r_combos: continue\n",
    "    test_df = {'w': [], 'peg': [], 'r': [], 'qc': [], 'qd': []}\n",
    "    for qc in qcs:\n",
    "        test_df['w'].append(w)\n",
    "        test_df['peg'].append(peg)\n",
    "        test_df['r'].append(r)\n",
    "        test_df['qc'].append(qc)\n",
    "        test_df['qd'].append(qc / r)\n",
    "    test_df = pd.DataFrame(test_df)\n",
    "    test_df['uc'] = test_df['qc'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "    test_df['ud'] = test_df['qd'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "    test_df['momentumc'] = 998 * test_df['uc'] ** 2 / (1e-3 * 0.6)\n",
    "    test_df['momentumd'] = 1.29 * test_df['ud'] ** 2 / (1e-3 * 0.6)\n",
    "    test_df['viscosityc'] = (0.2563 * test_df['peg'] ** 1.7663 + 0.7890) * 1e-3 * test_df['uc'] / (1e-3 * 0.6) ** 2\n",
    "    test_df['viscosityd'] = 18.6 * 1e-6 * test_df['ud'] / (1e-3 * 0.6) ** 2\n",
    "    test_df['interfacec'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "    test_df['interfaced'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "    test_df['Wo/w'] = test_df['w'] / 3\n",
    "    test_df['qc/qd'] = test_df['qc'] / test_df['qd']\n",
    "    test_df['rec'] = test_df['momentumc'] / test_df['viscosityc']\n",
    "    test_df['red'] = test_df['momentumd'] / test_df['viscosityd']\n",
    "    test_df['cac'] = test_df['viscosityc'] / test_df['interfacec']\n",
    "    test_df['cad'] = test_df['viscosityd'] / test_df['interfaced']\n",
    "    test_df['wec'] = test_df['momentumc'] / test_df['interfacec']\n",
    "    test_df['wed'] = test_df['momentumd'] / test_df['interfaced']\n",
    "    cand_df['w'].append(w)\n",
    "    cand_df['peg'].append(peg)\n",
    "    cand_df['r'].append(r)\n",
    "    o_preds = []\n",
    "    d_preds = []\n",
    "    p_preds = []\n",
    "    for i in range(len(di_models)):\n",
    "        test_df['di/Wi'] = di_models[i].predict(test_df[cols])\n",
    "        o_preds.append(o_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "        d_preds.append(d_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "        p_preds.append(p_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "    cand_df['o_uncertainty'].append(np.stack(o_preds).std(axis=0).mean())\n",
    "    cand_df['d_uncertainty'].append(np.stack(d_preds).std(axis=0).mean())\n",
    "    cand_df['p_uncertainty'].append(np.stack(p_preds).std(axis=0).mean() / df['post_d32_polydispersity'].max())\n",
    "cand_df = pd.DataFrame(cand_df)\n",
    "cand_df['uncertainty'] = cand_df['o_uncertainty'] + cand_df['d_uncertainty'] + cand_df['p_uncertainty']\n",
    "cand_df.sort_values('uncertainty', inplace=True, ascending=False)\n",
    "print(cand_df['uncertainty'].mean())\n",
    "cand_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration 6\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "df = pd.read_excel('./data/results.xlsx')\n",
    "df['uc'] = df['qc'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "df['ud'] = df['qd'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "df['momentumc'] = 998 * df['uc'] ** 2 / (1e-3 * 0.6)\n",
    "df['momentumd'] = 1.29 * df['ud'] ** 2 / (1e-3 * 0.6)\n",
    "df['viscosityc'] = (0.2563 * df['peg'] ** 1.7663 + 0.7890) * 1e-3 * df['uc'] / (1e-3 * 0.6) ** 2\n",
    "df['viscosityd'] = 18.6 * 1e-6 * df['ud'] / (1e-3 * 0.6) ** 2\n",
    "df['interfacec'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "df['interfaced'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "df['Wo/w'] = df['w'] / 3\n",
    "df['qc/qd'] = df['qc'] / df['qd']\n",
    "df['rec'] = df['momentumc'] / df['viscosityc']\n",
    "df['red'] = df['momentumd'] / df['viscosityd']\n",
    "df['cac'] = df['viscosityc'] / df['interfacec']\n",
    "df['cad'] = df['viscosityd'] / df['interfaced']\n",
    "df['wec'] = df['momentumc'] / df['interfacec']\n",
    "df['wed'] = df['momentumd'] / df['interfaced']\n",
    "\n",
    "w_peg_r_iter6 = {\n",
    "    'w':   [6, 6, 10, 10, 10, 10, 15, 15, 15, 15, 10, 10, 6, 15, 15, 15, 6, 15],\n",
    "    'peg': [0, 5,  0,  5, 10, 15,  0,  5, 10, 15, 10, 10, 5,  0,  0,  0, 0,  5],\n",
    "    'r':   [2, 3,  1,  2,  3,  4,  3,  4,  5,  2,  5,  7, 7,  6,  7,  8, 1,  4],\n",
    "}\n",
    "ridxs = []\n",
    "for w, peg, r in zip(w_peg_r_iter6['w'], w_peg_r_iter6['peg'], w_peg_r_iter6['r']):\n",
    "    ridxs.extend(df[(df['w'] == w) & (df['peg'] == peg) & (df['r'] == r)].index)\n",
    "df = df.iloc[ridxs]\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== di/Wi ================\n",
      "mean rmse: 0.144\tmean r2: 0.858\n",
      "======================================\n",
      "\n",
      "=============== occurrence ================\n",
      "mean p: 0.850\t\tmean macro_p: 0.841\n",
      "mean r: 0.850\t\tmean macro_r: 0.852\n",
      "===========================================\n",
      "\n",
      "=============== do/Wo ================\n",
      "mean rmse: 0.058\tmean r2: 0.940\n",
      "======================================\n",
      "\n",
      "=============== sigma ================\n",
      "mean rmse: 4.250\tmean r2: 0.025\n",
      "======================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['Wo/w', 'qc/qd', 'rec', 'red', 'cac', 'cad', 'wec', 'wed']\n",
    "score = {'di_rmse': [], 'di_r2': [], 'p': [], 'macro_p': [], 'r': [], 'macro_r': [], 'd_rmse': [], 'd_r2': [], 'p_rmse': [], 'p_r2': []}\n",
    "di_models = []\n",
    "o_models = []\n",
    "d_models = []\n",
    "p_models = []\n",
    "for i in range(10):\n",
    "    kfold = KFold(5, shuffle=True, random_state=i)\n",
    "    for fold in range(5):\n",
    "        train_idxs, test_idxs = list(kfold.split(df[cols], df['state']))[fold]\n",
    "        train_df = df.iloc[train_idxs].copy()\n",
    "        test_df = df.iloc[test_idxs].copy()\n",
    "        train_x, test_x = train_df[cols], test_df[cols]\n",
    "        train_y_di = (train_df['prev_d32'] / 0.6).to_numpy()\n",
    "        test_y_di = (test_df['prev_d32'] / 0.6).to_numpy()\n",
    "        di_model = RandomForestRegressor(random_state=12)\n",
    "        di_model.fit(train_x, train_y_di)\n",
    "        di_models.append(di_model)\n",
    "        test_p_di = di_model.predict(test_x)\n",
    "        score['di_rmse'].append(np.round(((test_p_di - test_y_di)**2).mean()**0.5, 4))\n",
    "        score['di_r2'].append(np.round(r2_score(test_y_di, test_p_di), 4))\n",
    "        train_df['di/Wi'] = di_model.predict(train_df[cols])\n",
    "        test_df['di/Wi'] = di_model.predict(test_df[cols])\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_o = train_df['state'].to_numpy()\n",
    "        test_y_o = test_df['state'].to_numpy()\n",
    "        o_model = RandomForestClassifier(random_state=3)\n",
    "        o_model.fit(train_x, train_y_o)\n",
    "        o_models.append(o_model)\n",
    "        test_p_o = o_model.predict(test_x)\n",
    "        p_weight = 1 / 2 / np.array([(test_p_o == i).sum() for i in test_p_o])\n",
    "        r_weight = 1 / 2 / np.array([(test_y_o == i).sum() for i in test_y_o])\n",
    "        score['p'].append(np.round((test_p_o == test_y_o).mean(), 4))\n",
    "        score['r'].append(np.round((test_p_o == test_y_o).mean(), 4))\n",
    "        score['macro_p'].append(np.round(((test_p_o == test_y_o) * p_weight).sum(), 4))\n",
    "        score['macro_r'].append(np.round(((test_p_o == test_y_o) * r_weight).sum(), 4))\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_d = (train_df['post_d32'] / (0.1 * train_df['w'])).to_numpy()\n",
    "        test_y_d = (test_df['post_d32'] / (0.1 * test_df['w'])).to_numpy()\n",
    "        d_model = RandomForestRegressor(random_state=12)\n",
    "        d_model.fit(train_x, train_y_d)\n",
    "        d_models.append(d_model)\n",
    "        test_p_d = d_model.predict(test_x)\n",
    "        score['d_rmse'].append(np.round(((test_p_d - test_y_d)**2).mean()**0.5, 4))\n",
    "        score['d_r2'].append(np.round(r2_score(test_y_d, test_p_d), 4))\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_p = train_df['post_d32_polydispersity'].to_numpy()\n",
    "        test_y_p = test_df['post_d32_polydispersity'].to_numpy()\n",
    "        p_model = RandomForestRegressor(random_state=12)\n",
    "        p_model.fit(train_x, train_y_p)\n",
    "        p_models.append(p_model)\n",
    "        test_p_p = p_model.predict(test_x)\n",
    "        score['p_rmse'].append(np.round(((test_p_p - test_y_p)**2).mean()**0.5, 4))\n",
    "        score['p_r2'].append(np.round(r2_score(test_y_p, test_p_p), 4))\n",
    "\n",
    "print('=============== di/Wi ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['di_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['di_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')\n",
    "\n",
    "print('=============== occurrence ================')\n",
    "print('mean p: %.3f' % np.mean(score['p']), end='\\t\\t')\n",
    "print('mean macro_p: %.3f' % np.mean(score['macro_p']), end='\\n')\n",
    "print('mean r: %.3f' % np.mean(score['r']), end='\\t\\t')\n",
    "print('mean macro_r: %.3f' % np.mean(score['macro_r']), end='\\n')\n",
    "print('===========================================', end='\\n\\n')\n",
    "\n",
    "print('=============== do/Wo ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['d_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['d_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')\n",
    "\n",
    "print('=============== sigma ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['p_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['p_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12365792225791586\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w</th>\n",
       "      <th>peg</th>\n",
       "      <th>r</th>\n",
       "      <th>o_uncertainty</th>\n",
       "      <th>d_uncertainty</th>\n",
       "      <th>p_uncertainty</th>\n",
       "      <th>uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0.237980</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.041287</td>\n",
       "      <td>0.287567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.197980</td>\n",
       "      <td>0.022999</td>\n",
       "      <td>0.020339</td>\n",
       "      <td>0.241318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.191652</td>\n",
       "      <td>0.018829</td>\n",
       "      <td>0.021509</td>\n",
       "      <td>0.231990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.195959</td>\n",
       "      <td>0.012565</td>\n",
       "      <td>0.018365</td>\n",
       "      <td>0.226889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.177980</td>\n",
       "      <td>0.017190</td>\n",
       "      <td>0.019827</td>\n",
       "      <td>0.214996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.171652</td>\n",
       "      <td>0.019395</td>\n",
       "      <td>0.022127</td>\n",
       "      <td>0.213173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.031138</td>\n",
       "      <td>0.082729</td>\n",
       "      <td>0.193867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.151652</td>\n",
       "      <td>0.013241</td>\n",
       "      <td>0.019273</td>\n",
       "      <td>0.184165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.037267</td>\n",
       "      <td>0.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.022075</td>\n",
       "      <td>0.020445</td>\n",
       "      <td>0.182521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     w  peg  r  o_uncertainty  d_uncertainty  p_uncertainty  uncertainty\n",
       "55  15   15  4       0.237980       0.008301       0.041287     0.287567\n",
       "22  10    5  5       0.197980       0.022999       0.020339     0.241318\n",
       "44  15    5  7       0.191652       0.018829       0.021509     0.231990\n",
       "9    6    5  5       0.195959       0.012565       0.018365     0.226889\n",
       "43  15    5  6       0.177980       0.017190       0.019827     0.214996\n",
       "45  15    5  8       0.171652       0.019395       0.022127     0.213173\n",
       "12  10    0  2       0.080000       0.031138       0.082729     0.193867\n",
       "10   6    5  6       0.151652       0.013241       0.019273     0.184165\n",
       "54  15   15  3       0.140000       0.006066       0.037267     0.183333\n",
       "23  10    5  6       0.140000       0.022075       0.020445     0.182521"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "qcs = [200, 400, 600, 800, 1000]\n",
    "ws = [6, 10, 15]\n",
    "pegs = [0, 5, 10, 15]\n",
    "rs = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "exp_w_peg_r_combos = list(zip(w_peg_r_iter6['w'], w_peg_r_iter6['peg'], w_peg_r_iter6['r']))\n",
    "cand_df = {'w': [], 'peg': [], 'r': [], 'o_uncertainty': [], 'd_uncertainty': [], 'p_uncertainty': []}\n",
    "for w, peg, r in itertools.product(ws, pegs, rs):\n",
    "    if (w, peg, r) in exp_w_peg_r_combos: continue\n",
    "    test_df = {'w': [], 'peg': [], 'r': [], 'qc': [], 'qd': []}\n",
    "    for qc in qcs:\n",
    "        test_df['w'].append(w)\n",
    "        test_df['peg'].append(peg)\n",
    "        test_df['r'].append(r)\n",
    "        test_df['qc'].append(qc)\n",
    "        test_df['qd'].append(qc / r)\n",
    "    test_df = pd.DataFrame(test_df)\n",
    "    test_df['uc'] = test_df['qc'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "    test_df['ud'] = test_df['qd'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "    test_df['momentumc'] = 998 * test_df['uc'] ** 2 / (1e-3 * 0.6)\n",
    "    test_df['momentumd'] = 1.29 * test_df['ud'] ** 2 / (1e-3 * 0.6)\n",
    "    test_df['viscosityc'] = (0.2563 * test_df['peg'] ** 1.7663 + 0.7890) * 1e-3 * test_df['uc'] / (1e-3 * 0.6) ** 2\n",
    "    test_df['viscosityd'] = 18.6 * 1e-6 * test_df['ud'] / (1e-3 * 0.6) ** 2\n",
    "    test_df['interfacec'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "    test_df['interfaced'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "    test_df['Wo/w'] = test_df['w'] / 3\n",
    "    test_df['qc/qd'] = test_df['qc'] / test_df['qd']\n",
    "    test_df['rec'] = test_df['momentumc'] / test_df['viscosityc']\n",
    "    test_df['red'] = test_df['momentumd'] / test_df['viscosityd']\n",
    "    test_df['cac'] = test_df['viscosityc'] / test_df['interfacec']\n",
    "    test_df['cad'] = test_df['viscosityd'] / test_df['interfaced']\n",
    "    test_df['wec'] = test_df['momentumc'] / test_df['interfacec']\n",
    "    test_df['wed'] = test_df['momentumd'] / test_df['interfaced']\n",
    "    cand_df['w'].append(w)\n",
    "    cand_df['peg'].append(peg)\n",
    "    cand_df['r'].append(r)\n",
    "    o_preds = []\n",
    "    d_preds = []\n",
    "    p_preds = []\n",
    "    for i in range(len(di_models)):\n",
    "        test_df['di/Wi'] = di_models[i].predict(test_df[cols])\n",
    "        o_preds.append(o_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "        d_preds.append(d_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "        p_preds.append(p_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "    cand_df['o_uncertainty'].append(np.stack(o_preds).std(axis=0).mean())\n",
    "    cand_df['d_uncertainty'].append(np.stack(d_preds).std(axis=0).mean())\n",
    "    cand_df['p_uncertainty'].append(np.stack(p_preds).std(axis=0).mean() / df['post_d32_polydispersity'].max())\n",
    "cand_df = pd.DataFrame(cand_df)\n",
    "cand_df['uncertainty'] = cand_df['o_uncertainty'] + cand_df['d_uncertainty'] + cand_df['p_uncertainty']\n",
    "cand_df.sort_values('uncertainty', inplace=True, ascending=False)\n",
    "print(cand_df['uncertainty'].mean())\n",
    "cand_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration 7\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "df = pd.read_excel('./data/results.xlsx')\n",
    "df['uc'] = df['qc'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "df['ud'] = df['qd'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "df['momentumc'] = 998 * df['uc'] ** 2 / (1e-3 * 0.6)\n",
    "df['momentumd'] = 1.29 * df['ud'] ** 2 / (1e-3 * 0.6)\n",
    "df['viscosityc'] = (0.2563 * df['peg'] ** 1.7663 + 0.7890) * 1e-3 * df['uc'] / (1e-3 * 0.6) ** 2\n",
    "df['viscosityd'] = 18.6 * 1e-6 * df['ud'] / (1e-3 * 0.6) ** 2\n",
    "df['interfacec'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "df['interfaced'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "df['Wo/w'] = df['w'] / 3\n",
    "df['qc/qd'] = df['qc'] / df['qd']\n",
    "df['rec'] = df['momentumc'] / df['viscosityc']\n",
    "df['red'] = df['momentumd'] / df['viscosityd']\n",
    "df['cac'] = df['viscosityc'] / df['interfacec']\n",
    "df['cad'] = df['viscosityd'] / df['interfaced']\n",
    "df['wec'] = df['momentumc'] / df['interfacec']\n",
    "df['wed'] = df['momentumd'] / df['interfaced']\n",
    "\n",
    "w_peg_r_iter7 = {\n",
    "    'w':   [6, 6, 10, 10, 10, 10, 15, 15, 15, 15, 10, 10, 6, 15, 15, 15, 6, 15, 15],\n",
    "    'peg': [0, 5,  0,  5, 10, 15,  0,  5, 10, 15, 10, 10, 5,  0,  0,  0, 0,  5, 15],\n",
    "    'r':   [2, 3,  1,  2,  3,  4,  3,  4,  5,  2,  5,  7, 7,  6,  7,  8, 1,  4,  4],\n",
    "}\n",
    "ridxs = []\n",
    "for w, peg, r in zip(w_peg_r_iter7['w'], w_peg_r_iter7['peg'], w_peg_r_iter7['r']):\n",
    "    ridxs.extend(df[(df['w'] == w) & (df['peg'] == peg) & (df['r'] == r)].index)\n",
    "df = df.iloc[ridxs]\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== di/Wi ================\n",
      "mean rmse: 0.134\tmean r2: 0.929\n",
      "======================================\n",
      "\n",
      "=============== occurrence ================\n",
      "mean p: 0.833\t\tmean macro_p: 0.845\n",
      "mean r: 0.833\t\tmean macro_r: 0.810\n",
      "===========================================\n",
      "\n",
      "=============== do/Wo ================\n",
      "mean rmse: 0.054\tmean r2: 0.965\n",
      "======================================\n",
      "\n",
      "=============== sigma ================\n",
      "mean rmse: 3.041\tmean r2: 0.617\n",
      "======================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['Wo/w', 'qc/qd', 'rec', 'red', 'cac', 'cad', 'wec', 'wed']\n",
    "score = {'di_rmse': [], 'di_r2': [], 'p': [], 'macro_p': [], 'r': [], 'macro_r': [], 'd_rmse': [], 'd_r2': [], 'p_rmse': [], 'p_r2': []}\n",
    "di_models = []\n",
    "o_models = []\n",
    "d_models = []\n",
    "p_models = []\n",
    "for i in range(10):\n",
    "    kfold = KFold(5, shuffle=True, random_state=i)\n",
    "    for fold in range(5):\n",
    "        train_idxs, test_idxs = list(kfold.split(df[cols], df['state']))[fold]\n",
    "        train_df = df.iloc[train_idxs].copy()\n",
    "        test_df = df.iloc[test_idxs].copy()\n",
    "        train_x, test_x = train_df[cols], test_df[cols]\n",
    "        train_y_di = (train_df['prev_d32'] / 0.6).to_numpy()\n",
    "        test_y_di = (test_df['prev_d32'] / 0.6).to_numpy()\n",
    "        di_model = RandomForestRegressor(random_state=12)\n",
    "        di_model.fit(train_x, train_y_di)\n",
    "        di_models.append(di_model)\n",
    "        test_p_di = di_model.predict(test_x)\n",
    "        score['di_rmse'].append(np.round(((test_p_di - test_y_di)**2).mean()**0.5, 4))\n",
    "        score['di_r2'].append(np.round(r2_score(test_y_di, test_p_di), 4))\n",
    "        train_df['di/Wi'] = di_model.predict(train_df[cols])\n",
    "        test_df['di/Wi'] = di_model.predict(test_df[cols])\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_o = train_df['state'].to_numpy()\n",
    "        test_y_o = test_df['state'].to_numpy()\n",
    "        o_model = RandomForestClassifier(random_state=3)\n",
    "        o_model.fit(train_x, train_y_o)\n",
    "        o_models.append(o_model)\n",
    "        test_p_o = o_model.predict(test_x)\n",
    "        p_weight = 1 / 2 / np.array([(test_p_o == i).sum() for i in test_p_o])\n",
    "        r_weight = 1 / 2 / np.array([(test_y_o == i).sum() for i in test_y_o])\n",
    "        score['p'].append(np.round((test_p_o == test_y_o).mean(), 4))\n",
    "        score['r'].append(np.round((test_p_o == test_y_o).mean(), 4))\n",
    "        score['macro_p'].append(np.round(((test_p_o == test_y_o) * p_weight).sum(), 4))\n",
    "        score['macro_r'].append(np.round(((test_p_o == test_y_o) * r_weight).sum(), 4))\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_d = (train_df['post_d32'] / (0.1 * train_df['w'])).to_numpy()\n",
    "        test_y_d = (test_df['post_d32'] / (0.1 * test_df['w'])).to_numpy()\n",
    "        d_model = RandomForestRegressor(random_state=12)\n",
    "        d_model.fit(train_x, train_y_d)\n",
    "        d_models.append(d_model)\n",
    "        test_p_d = d_model.predict(test_x)\n",
    "        score['d_rmse'].append(np.round(((test_p_d - test_y_d)**2).mean()**0.5, 4))\n",
    "        score['d_r2'].append(np.round(r2_score(test_y_d, test_p_d), 4))\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_p = train_df['post_d32_polydispersity'].to_numpy()\n",
    "        test_y_p = test_df['post_d32_polydispersity'].to_numpy()\n",
    "        p_model = RandomForestRegressor(random_state=12)\n",
    "        p_model.fit(train_x, train_y_p)\n",
    "        p_models.append(p_model)\n",
    "        test_p_p = p_model.predict(test_x)\n",
    "        score['p_rmse'].append(np.round(((test_p_p - test_y_p)**2).mean()**0.5, 4))\n",
    "        score['p_r2'].append(np.round(r2_score(test_y_p, test_p_p), 4))\n",
    "\n",
    "print('=============== di/Wi ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['di_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['di_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')\n",
    "\n",
    "print('=============== occurrence ================')\n",
    "print('mean p: %.3f' % np.mean(score['p']), end='\\t\\t')\n",
    "print('mean macro_p: %.3f' % np.mean(score['macro_p']), end='\\n')\n",
    "print('mean r: %.3f' % np.mean(score['r']), end='\\t\\t')\n",
    "print('mean macro_r: %.3f' % np.mean(score['macro_r']), end='\\n')\n",
    "print('===========================================', end='\\n\\n')\n",
    "\n",
    "print('=============== do/Wo ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['d_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['d_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')\n",
    "\n",
    "print('=============== sigma ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['p_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['p_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12431713256899395\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w</th>\n",
       "      <th>peg</th>\n",
       "      <th>r</th>\n",
       "      <th>o_uncertainty</th>\n",
       "      <th>d_uncertainty</th>\n",
       "      <th>p_uncertainty</th>\n",
       "      <th>uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.033005</td>\n",
       "      <td>0.028695</td>\n",
       "      <td>0.261700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.191652</td>\n",
       "      <td>0.028286</td>\n",
       "      <td>0.022317</td>\n",
       "      <td>0.242255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.197980</td>\n",
       "      <td>0.022497</td>\n",
       "      <td>0.018231</td>\n",
       "      <td>0.238708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.189631</td>\n",
       "      <td>0.026117</td>\n",
       "      <td>0.019135</td>\n",
       "      <td>0.234883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.183303</td>\n",
       "      <td>0.022361</td>\n",
       "      <td>0.018126</td>\n",
       "      <td>0.223790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.151652</td>\n",
       "      <td>0.023784</td>\n",
       "      <td>0.018250</td>\n",
       "      <td>0.193686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.028007</td>\n",
       "      <td>0.022818</td>\n",
       "      <td>0.190825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.027574</td>\n",
       "      <td>0.022215</td>\n",
       "      <td>0.189789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.027213</td>\n",
       "      <td>0.018328</td>\n",
       "      <td>0.185541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.042859</td>\n",
       "      <td>0.059948</td>\n",
       "      <td>0.182808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     w  peg  r  o_uncertainty  d_uncertainty  p_uncertainty  uncertainty\n",
       "39  15    5  1       0.200000       0.033005       0.028695     0.261700\n",
       "22  10    5  5       0.191652       0.028286       0.022317     0.242255\n",
       "43  15    5  6       0.197980       0.022497       0.018231     0.238708\n",
       "9    6    5  5       0.189631       0.026117       0.019135     0.234883\n",
       "44  15    5  7       0.183303       0.022361       0.018126     0.223790\n",
       "45  15    5  8       0.151652       0.023784       0.018250     0.193686\n",
       "24  10    5  7       0.140000       0.028007       0.022818     0.190825\n",
       "23  10    5  6       0.140000       0.027574       0.022215     0.189789\n",
       "10   6    5  6       0.140000       0.027213       0.018328     0.185541\n",
       "14  10    0  4       0.080000       0.042859       0.059948     0.182808"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "qcs = [200, 400, 600, 800, 1000]\n",
    "ws = [6, 10, 15]\n",
    "pegs = [0, 5, 10, 15]\n",
    "rs = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "exp_w_peg_r_combos = list(zip(w_peg_r_iter7['w'], w_peg_r_iter7['peg'], w_peg_r_iter7['r']))\n",
    "cand_df = {'w': [], 'peg': [], 'r': [], 'o_uncertainty': [], 'd_uncertainty': [], 'p_uncertainty': []}\n",
    "for w, peg, r in itertools.product(ws, pegs, rs):\n",
    "    if (w, peg, r) in exp_w_peg_r_combos: continue\n",
    "    test_df = {'w': [], 'peg': [], 'r': [], 'qc': [], 'qd': []}\n",
    "    for qc in qcs:\n",
    "        test_df['w'].append(w)\n",
    "        test_df['peg'].append(peg)\n",
    "        test_df['r'].append(r)\n",
    "        test_df['qc'].append(qc)\n",
    "        test_df['qd'].append(qc / r)\n",
    "    test_df = pd.DataFrame(test_df)\n",
    "    test_df['uc'] = test_df['qc'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "    test_df['ud'] = test_df['qd'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "    test_df['momentumc'] = 998 * test_df['uc'] ** 2 / (1e-3 * 0.6)\n",
    "    test_df['momentumd'] = 1.29 * test_df['ud'] ** 2 / (1e-3 * 0.6)\n",
    "    test_df['viscosityc'] = (0.2563 * test_df['peg'] ** 1.7663 + 0.7890) * 1e-3 * test_df['uc'] / (1e-3 * 0.6) ** 2\n",
    "    test_df['viscosityd'] = 18.6 * 1e-6 * test_df['ud'] / (1e-3 * 0.6) ** 2\n",
    "    test_df['interfacec'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "    test_df['interfaced'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "    test_df['Wo/w'] = test_df['w'] / 3\n",
    "    test_df['qc/qd'] = test_df['qc'] / test_df['qd']\n",
    "    test_df['rec'] = test_df['momentumc'] / test_df['viscosityc']\n",
    "    test_df['red'] = test_df['momentumd'] / test_df['viscosityd']\n",
    "    test_df['cac'] = test_df['viscosityc'] / test_df['interfacec']\n",
    "    test_df['cad'] = test_df['viscosityd'] / test_df['interfaced']\n",
    "    test_df['wec'] = test_df['momentumc'] / test_df['interfacec']\n",
    "    test_df['wed'] = test_df['momentumd'] / test_df['interfaced']\n",
    "    cand_df['w'].append(w)\n",
    "    cand_df['peg'].append(peg)\n",
    "    cand_df['r'].append(r)\n",
    "    o_preds = []\n",
    "    d_preds = []\n",
    "    p_preds = []\n",
    "    for i in range(len(di_models)):\n",
    "        test_df['di/Wi'] = di_models[i].predict(test_df[cols])\n",
    "        o_preds.append(o_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "        d_preds.append(d_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "        p_preds.append(p_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "    cand_df['o_uncertainty'].append(np.stack(o_preds).std(axis=0).mean())\n",
    "    cand_df['d_uncertainty'].append(np.stack(d_preds).std(axis=0).mean())\n",
    "    cand_df['p_uncertainty'].append(np.stack(p_preds).std(axis=0).mean() / df['post_d32_polydispersity'].max())\n",
    "cand_df = pd.DataFrame(cand_df)\n",
    "cand_df['uncertainty'] = cand_df['o_uncertainty'] + cand_df['d_uncertainty'] + cand_df['p_uncertainty']\n",
    "cand_df.sort_values('uncertainty', inplace=True, ascending=False)\n",
    "print(cand_df['uncertainty'].mean())\n",
    "cand_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration 8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "df = pd.read_excel('./data/results.xlsx')\n",
    "df['uc'] = df['qc'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "df['ud'] = df['qd'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "df['momentumc'] = 998 * df['uc'] ** 2 / (1e-3 * 0.6)\n",
    "df['momentumd'] = 1.29 * df['ud'] ** 2 / (1e-3 * 0.6)\n",
    "df['viscosityc'] = (0.2563 * df['peg'] ** 1.7663 + 0.7890) * 1e-3 * df['uc'] / (1e-3 * 0.6) ** 2\n",
    "df['viscosityd'] = 18.6 * 1e-6 * df['ud'] / (1e-3 * 0.6) ** 2\n",
    "df['interfacec'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "df['interfaced'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "df['Wo/w'] = df['w'] / 3\n",
    "df['qc/qd'] = df['qc'] / df['qd']\n",
    "df['rec'] = df['momentumc'] / df['viscosityc']\n",
    "df['red'] = df['momentumd'] / df['viscosityd']\n",
    "df['cac'] = df['viscosityc'] / df['interfacec']\n",
    "df['cad'] = df['viscosityd'] / df['interfaced']\n",
    "df['wec'] = df['momentumc'] / df['interfacec']\n",
    "df['wed'] = df['momentumd'] / df['interfaced']\n",
    "\n",
    "w_peg_r_iter8 = {\n",
    "    'w':   [6, 6, 10, 10, 10, 10, 15, 15, 15, 15, 10, 10, 6, 15, 15, 15, 6, 15, 15, 15],\n",
    "    'peg': [0, 5,  0,  5, 10, 15,  0,  5, 10, 15, 10, 10, 5,  0,  0,  0, 0,  5, 15,  5],\n",
    "    'r':   [2, 3,  1,  2,  3,  4,  3,  4,  5,  2,  5,  7, 7,  6,  7,  8, 1,  4,  4,  5],\n",
    "}\n",
    "ridxs = []\n",
    "for w, peg, r in zip(w_peg_r_iter8['w'], w_peg_r_iter8['peg'], w_peg_r_iter8['r']):\n",
    "    ridxs.extend(df[(df['w'] == w) & (df['peg'] == peg) & (df['r'] == r)].index)\n",
    "df = df.iloc[ridxs]\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== di/Wi ================\n",
      "mean rmse: 0.111\tmean r2: 0.948\n",
      "======================================\n",
      "\n",
      "=============== occurrence ================\n",
      "mean p: 0.891\t\tmean macro_p: 0.893\n",
      "mean r: 0.891\t\tmean macro_r: 0.892\n",
      "===========================================\n",
      "\n",
      "=============== do/Wo ================\n",
      "mean rmse: 0.048\tmean r2: 0.974\n",
      "======================================\n",
      "\n",
      "=============== sigma ================\n",
      "mean rmse: 2.997\tmean r2: 0.690\n",
      "======================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['Wo/w', 'qc/qd', 'rec', 'red', 'cac', 'cad', 'wec', 'wed']\n",
    "score = {'di_rmse': [], 'di_r2': [], 'p': [], 'macro_p': [], 'r': [], 'macro_r': [], 'd_rmse': [], 'd_r2': [], 'p_rmse': [], 'p_r2': []}\n",
    "di_models = []\n",
    "o_models = []\n",
    "d_models = []\n",
    "p_models = []\n",
    "for i in range(10):\n",
    "    kfold = KFold(5, shuffle=True, random_state=i)\n",
    "    for fold in range(5):\n",
    "        train_idxs, test_idxs = list(kfold.split(df[cols], df['state']))[fold]\n",
    "        train_df = df.iloc[train_idxs].copy()\n",
    "        test_df = df.iloc[test_idxs].copy()\n",
    "        train_x, test_x = train_df[cols], test_df[cols]\n",
    "        train_y_di = (train_df['prev_d32'] / 0.6).to_numpy()\n",
    "        test_y_di = (test_df['prev_d32'] / 0.6).to_numpy()\n",
    "        di_model = RandomForestRegressor(random_state=12)\n",
    "        di_model.fit(train_x, train_y_di)\n",
    "        di_models.append(di_model)\n",
    "        test_p_di = di_model.predict(test_x)\n",
    "        score['di_rmse'].append(np.round(((test_p_di - test_y_di)**2).mean()**0.5, 4))\n",
    "        score['di_r2'].append(np.round(r2_score(test_y_di, test_p_di), 4))\n",
    "        train_df['di/Wi'] = di_model.predict(train_df[cols])\n",
    "        test_df['di/Wi'] = di_model.predict(test_df[cols])\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_o = train_df['state'].to_numpy()\n",
    "        test_y_o = test_df['state'].to_numpy()\n",
    "        o_model = RandomForestClassifier(random_state=15)\n",
    "        o_model.fit(train_x, train_y_o)\n",
    "        o_models.append(o_model)\n",
    "        test_p_o = o_model.predict(test_x)\n",
    "        p_weight = 1 / 2 / np.array([(test_p_o == i).sum() for i in test_p_o])\n",
    "        r_weight = 1 / 2 / np.array([(test_y_o == i).sum() for i in test_y_o])\n",
    "        score['p'].append(np.round((test_p_o == test_y_o).mean(), 4))\n",
    "        score['r'].append(np.round((test_p_o == test_y_o).mean(), 4))\n",
    "        score['macro_p'].append(np.round(((test_p_o == test_y_o) * p_weight).sum(), 4))\n",
    "        score['macro_r'].append(np.round(((test_p_o == test_y_o) * r_weight).sum(), 4))\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_d = (train_df['post_d32'] / (0.1 * train_df['w'])).to_numpy()\n",
    "        test_y_d = (test_df['post_d32'] / (0.1 * test_df['w'])).to_numpy()\n",
    "        d_model = RandomForestRegressor(random_state=12)\n",
    "        d_model.fit(train_x, train_y_d)\n",
    "        d_models.append(d_model)\n",
    "        test_p_d = d_model.predict(test_x)\n",
    "        score['d_rmse'].append(np.round(((test_p_d - test_y_d)**2).mean()**0.5, 4))\n",
    "        score['d_r2'].append(np.round(r2_score(test_y_d, test_p_d), 4))\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_p = train_df['post_d32_polydispersity'].to_numpy()\n",
    "        test_y_p = test_df['post_d32_polydispersity'].to_numpy()\n",
    "        p_model = RandomForestRegressor(random_state=12)\n",
    "        p_model.fit(train_x, train_y_p)\n",
    "        p_models.append(p_model)\n",
    "        test_p_p = p_model.predict(test_x)\n",
    "        score['p_rmse'].append(np.round(((test_p_p - test_y_p)**2).mean()**0.5, 4))\n",
    "        score['p_r2'].append(np.round(r2_score(test_y_p, test_p_p), 4))\n",
    "\n",
    "print('=============== di/Wi ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['di_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['di_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')\n",
    "\n",
    "print('=============== occurrence ================')\n",
    "print('mean p: %.3f' % np.mean(score['p']), end='\\t\\t')\n",
    "print('mean macro_p: %.3f' % np.mean(score['macro_p']), end='\\n')\n",
    "print('mean r: %.3f' % np.mean(score['r']), end='\\t\\t')\n",
    "print('mean macro_r: %.3f' % np.mean(score['macro_r']), end='\\n')\n",
    "print('===========================================', end='\\n\\n')\n",
    "\n",
    "print('=============== do/Wo ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['d_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['d_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')\n",
    "\n",
    "print('=============== sigma ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['p_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['p_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14846030562354412\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w</th>\n",
       "      <th>peg</th>\n",
       "      <th>r</th>\n",
       "      <th>o_uncertainty</th>\n",
       "      <th>d_uncertainty</th>\n",
       "      <th>p_uncertainty</th>\n",
       "      <th>uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.287611</td>\n",
       "      <td>0.029026</td>\n",
       "      <td>0.017909</td>\n",
       "      <td>0.334545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.024849</td>\n",
       "      <td>0.017502</td>\n",
       "      <td>0.302351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.257980</td>\n",
       "      <td>0.025246</td>\n",
       "      <td>0.017626</td>\n",
       "      <td>0.300852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.257980</td>\n",
       "      <td>0.025071</td>\n",
       "      <td>0.017779</td>\n",
       "      <td>0.300830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.251652</td>\n",
       "      <td>0.028818</td>\n",
       "      <td>0.017092</td>\n",
       "      <td>0.297562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     w  peg  r  o_uncertainty  d_uncertainty  p_uncertainty  uncertainty\n",
       "10   6    5  6       0.287611       0.029026       0.017909     0.334545\n",
       "23  10    5  6       0.260000       0.024849       0.017502     0.302351\n",
       "45  15    5  8       0.257980       0.025246       0.017626     0.300852\n",
       "24  10    5  7       0.257980       0.025071       0.017779     0.300830\n",
       "11   6    5  8       0.251652       0.028818       0.017092     0.297562"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "qcs = [200, 400, 600, 800, 1000]\n",
    "ws = [6, 10, 15]\n",
    "pegs = [0, 5, 10, 15]\n",
    "rs = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "exp_w_peg_r_combos = list(zip(w_peg_r_iter7['w'], w_peg_r_iter7['peg'], w_peg_r_iter7['r']))\n",
    "cand_df = {'w': [], 'peg': [], 'r': [], 'o_uncertainty': [], 'd_uncertainty': [], 'p_uncertainty': []}\n",
    "for w, peg, r in itertools.product(ws, pegs, rs):\n",
    "    if (w, peg, r) in exp_w_peg_r_combos: continue\n",
    "    test_df = {'w': [], 'peg': [], 'r': [], 'qc': [], 'qd': []}\n",
    "    for qc in qcs:\n",
    "        test_df['w'].append(w)\n",
    "        test_df['peg'].append(peg)\n",
    "        test_df['r'].append(r)\n",
    "        test_df['qc'].append(qc)\n",
    "        test_df['qd'].append(qc / r)\n",
    "    test_df = pd.DataFrame(test_df)\n",
    "    test_df['uc'] = test_df['qc'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "    test_df['ud'] = test_df['qd'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "    test_df['momentumc'] = 998 * test_df['uc'] ** 2 / (1e-3 * 0.6)\n",
    "    test_df['momentumd'] = 1.29 * test_df['ud'] ** 2 / (1e-3 * 0.6)\n",
    "    test_df['viscosityc'] = (0.2563 * test_df['peg'] ** 1.7663 + 0.7890) * 1e-3 * test_df['uc'] / (1e-3 * 0.6) ** 2\n",
    "    test_df['viscosityd'] = 18.6 * 1e-6 * test_df['ud'] / (1e-3 * 0.6) ** 2\n",
    "    test_df['interfacec'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "    test_df['interfaced'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "    test_df['Wo/w'] = test_df['w'] / 3\n",
    "    test_df['qc/qd'] = test_df['qc'] / test_df['qd']\n",
    "    test_df['rec'] = test_df['momentumc'] / test_df['viscosityc']\n",
    "    test_df['red'] = test_df['momentumd'] / test_df['viscosityd']\n",
    "    test_df['cac'] = test_df['viscosityc'] / test_df['interfacec']\n",
    "    test_df['cad'] = test_df['viscosityd'] / test_df['interfaced']\n",
    "    test_df['wec'] = test_df['momentumc'] / test_df['interfacec']\n",
    "    test_df['wed'] = test_df['momentumd'] / test_df['interfaced']\n",
    "    cand_df['w'].append(w)\n",
    "    cand_df['peg'].append(peg)\n",
    "    cand_df['r'].append(r)\n",
    "    o_preds = []\n",
    "    d_preds = []\n",
    "    p_preds = []\n",
    "    for i in range(len(di_models)):\n",
    "        test_df['di/Wi'] = di_models[i].predict(test_df[cols])\n",
    "        o_preds.append(o_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "        d_preds.append(d_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "        p_preds.append(p_models[i].predict(test_df[cols + ['di/Wi']]))\n",
    "    cand_df['o_uncertainty'].append(np.stack(o_preds).std(axis=0).mean())\n",
    "    cand_df['d_uncertainty'].append(np.stack(d_preds).std(axis=0).mean())\n",
    "    cand_df['p_uncertainty'].append(np.stack(p_preds).std(axis=0).mean() / df['post_d32_polydispersity'].max())\n",
    "cand_df = pd.DataFrame(cand_df)\n",
    "cand_df['uncertainty'] = cand_df['o_uncertainty'] + cand_df['d_uncertainty'] + cand_df['p_uncertainty']\n",
    "cand_df.sort_values('uncertainty', inplace=True, ascending=False)\n",
    "print(cand_df['uncertainty'].mean())\n",
    "cand_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration 9\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "df = pd.read_excel('./data/results.xlsx')\n",
    "df['uc'] = df['qc'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "df['ud'] = df['qd'] / 60 / 1e6 / (1e-3 * 0.6) ** 2\n",
    "df['momentumc'] = 998 * df['uc'] ** 2 / (1e-3 * 0.6)\n",
    "df['momentumd'] = 1.29 * df['ud'] ** 2 / (1e-3 * 0.6)\n",
    "df['viscosityc'] = (0.2563 * df['peg'] ** 1.7663 + 0.7890) * 1e-3 * df['uc'] / (1e-3 * 0.6) ** 2\n",
    "df['viscosityd'] = 18.6 * 1e-6 * df['ud'] / (1e-3 * 0.6) ** 2\n",
    "df['interfacec'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "df['interfaced'] = 0.035 / (1e-3 * 0.6) ** 2\n",
    "df['Wo/w'] = df['w'] / 3\n",
    "df['qc/qd'] = df['qc'] / df['qd']\n",
    "df['rec'] = df['momentumc'] / df['viscosityc']\n",
    "df['red'] = df['momentumd'] / df['viscosityd']\n",
    "df['cac'] = df['viscosityc'] / df['interfacec']\n",
    "df['cad'] = df['viscosityd'] / df['interfaced']\n",
    "df['wec'] = df['momentumc'] / df['interfacec']\n",
    "df['wed'] = df['momentumd'] / df['interfaced']\n",
    "\n",
    "w_peg_r_iter9 = {\n",
    "    'w':   [6, 6, 10, 10, 10, 10, 15, 15, 15, 15, 10, 10, 6, 15, 15, 15, 6, 15, 15, 15, 10],\n",
    "    'peg': [0, 5,  0,  5, 10, 15,  0,  5, 10, 15, 10, 10, 5,  0,  0,  0, 0,  5, 15,  5,  5],\n",
    "    'r':   [2, 3,  1,  2,  3,  4,  3,  4,  5,  2,  5,  7, 7,  6,  7,  8, 1,  4,  4,  5,  6],\n",
    "}\n",
    "ridxs = []\n",
    "for w, peg, r in zip(w_peg_r_iter9['w'], w_peg_r_iter9['peg'], w_peg_r_iter9['r']):\n",
    "    ridxs.extend(df[(df['w'] == w) & (df['peg'] == peg) & (df['r'] == r)].index)\n",
    "df = df.iloc[ridxs]\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Wo/w', 'qc/qd', 'rec', 'red', 'cac', 'cad', 'wec', 'wed']\n",
    "score = {'di_rmse': [], 'di_r2': [], 'p': [], 'macro_p': [], 'r': [], 'macro_r': [], 'd_rmse': [], 'd_r2': [], 'p_rmse': [], 'p_r2': []}\n",
    "di_models = []\n",
    "o_models = []\n",
    "d_models = []\n",
    "p_models = []\n",
    "for i in range(10):\n",
    "    kfold = KFold(5, shuffle=True, random_state=i)\n",
    "    for fold in range(5):\n",
    "        train_idxs, test_idxs = list(kfold.split(df[cols], df['state']))[fold]\n",
    "        train_df = df.iloc[train_idxs].copy()\n",
    "        test_df = df.iloc[test_idxs].copy()\n",
    "        train_x, test_x = train_df[cols], test_df[cols]\n",
    "        train_y_di = (train_df['prev_d32'] / 0.6).to_numpy()\n",
    "        test_y_di = (test_df['prev_d32'] / 0.6).to_numpy()\n",
    "        di_model = RandomForestRegressor(random_state=12)\n",
    "        di_model.fit(train_x, train_y_di)\n",
    "        di_models.append(di_model)\n",
    "        test_p_di = di_model.predict(test_x)\n",
    "        score['di_rmse'].append(np.round(((test_p_di - test_y_di)**2).mean()**0.5, 4))\n",
    "        score['di_r2'].append(np.round(r2_score(test_y_di, test_p_di), 4))\n",
    "        train_df['di/Wi'] = di_model.predict(train_df[cols])\n",
    "        test_df['di/Wi'] = di_model.predict(test_df[cols])\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_o = train_df['state'].to_numpy()\n",
    "        test_y_o = test_df['state'].to_numpy()\n",
    "        o_model = RandomForestClassifier(random_state=12)\n",
    "        o_model.fit(train_x, train_y_o)\n",
    "        o_models.append(o_model)\n",
    "        test_p_o = o_model.predict(test_x)\n",
    "        p_weight = 1 / 2 / np.array([(test_p_o == i).sum() for i in test_p_o])\n",
    "        r_weight = 1 / 2 / np.array([(test_y_o == i).sum() for i in test_y_o])\n",
    "        score['p'].append(np.round((test_p_o == test_y_o).mean(), 4))\n",
    "        score['r'].append(np.round((test_p_o == test_y_o).mean(), 4))\n",
    "        score['macro_p'].append(np.round(((test_p_o == test_y_o) * p_weight).sum(), 4))\n",
    "        score['macro_r'].append(np.round(((test_p_o == test_y_o) * r_weight).sum(), 4))\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_d = (train_df['post_d32'] / (0.1 * train_df['w'])).to_numpy()\n",
    "        test_y_d = (test_df['post_d32'] / (0.1 * test_df['w'])).to_numpy()\n",
    "        d_model = RandomForestRegressor(random_state=12)\n",
    "        d_model.fit(train_x, train_y_d)\n",
    "        d_models.append(d_model)\n",
    "        test_p_d = d_model.predict(test_x)\n",
    "        score['d_rmse'].append(np.round(((test_p_d - test_y_d)**2).mean()**0.5, 4))\n",
    "        score['d_r2'].append(np.round(r2_score(test_y_d, test_p_d), 4))\n",
    "\n",
    "        train_x, test_x = train_df[cols], test_df[cols]\n",
    "        train_y_d = (train_df['post_d32'] / (train_df['di/Wi'] * 0.6)).to_numpy()\n",
    "        test_y_d = (test_df['post_d32'] / (test_df['di/Wi'] * 0.6)).to_numpy()\n",
    "        d_model = RandomForestRegressor(random_state=12)\n",
    "        d_model.fit(train_x, train_y_d)\n",
    "        d_models.append(d_model)\n",
    "        test_p_d = d_model.predict(test_x)\n",
    "        score['d_rmse'].append(np.round(((test_p_d - test_y_d)**2).mean()**0.5, 4))\n",
    "        score['d_r2'].append(np.round(r2_score(test_y_d, test_p_d), 4))\n",
    "\n",
    "        train_x, test_x = train_df[cols + ['di/Wi']], test_df[cols + ['di/Wi']]\n",
    "        train_y_p = train_df['post_d32_polydispersity'].to_numpy()\n",
    "        test_y_p = test_df['post_d32_polydispersity'].to_numpy()\n",
    "        p_model = RandomForestRegressor(random_state=12)\n",
    "        p_model.fit(train_x, train_y_p)\n",
    "        p_models.append(p_model)\n",
    "        test_p_p = p_model.predict(test_x)\n",
    "        score['p_rmse'].append(np.round(((test_p_p - test_y_p)**2).mean()**0.5, 4))\n",
    "        score['p_r2'].append(np.round(r2_score(test_y_p, test_p_p), 4))\n",
    "\n",
    "print('=============== di/Wi ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['di_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['di_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')\n",
    "\n",
    "print('=============== occurrence ================')\n",
    "print('mean p: %.3f' % np.mean(score['p']), end='\\t\\t')\n",
    "print('mean macro_p: %.3f' % np.mean(score['macro_p'][2:]), end='\\n')\n",
    "print('mean r: %.3f' % np.mean(score['r']), end='\\t\\t')\n",
    "print('mean macro_r: %.3f' % np.mean(score['macro_r'][2:]), end='\\n')\n",
    "print('===========================================', end='\\n\\n')\n",
    "\n",
    "print('=============== do/Wo ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['d_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['d_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')\n",
    "\n",
    "print('=============== sigma ================')\n",
    "print('mean rmse: %.3f' % np.mean(score['p_rmse']), end='\\t')\n",
    "print('mean r2: %.3f' % np.mean(score['p_r2']), end='\\n')\n",
    "print('======================================', end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fluid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
